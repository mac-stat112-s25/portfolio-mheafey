[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT112 Notebook",
    "section": "",
    "text": "Welcome\nWelcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "bw/bw-uni.html",
    "href": "bw/bw-uni.html",
    "title": "\n1  Univariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking univariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nlibrary(tidyverse)\nlibrary(mosaic)\nlibrary(fivethirtyeight)\n\n\ndata(bechdel)\nnew_bechdel &lt;- bechdel |&gt;\n  mutate(clean_test = factor(clean_test, c(\"nowomen\", \"notalk\", \"men\", \"dubious\", \"ok\"))) |&gt;\n  mutate(half_decades = cut(year, breaks = seq(1969, 2014, by = 5)))\n\n\nggplot(new_bechdel, aes(x = clean_test)) +\n  geom_bar(color = \"white\", fill = \"blue\") +\n  labs(title = \"Number of Movies Passing the Bechdel Test by Degree of Passing\", y = \"# of Movies\", x = \"Degree of Passing\")\n\n\n\nCreated by Madeleine Heafey",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-bi.html",
    "href": "bw/bw-bi.html",
    "title": "\n2  Bivariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking bivariate visualization. The visualization will not perfect the first time but you are expected to improve it throughout the semester especially after covering advanced topics such as effective viz.\n\n#|echo: true\n#| message: false\n#| warning: false\n#| code-fold: true\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\nAttaching package: 'mosaic'\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nlibrary(fivethirtyeight)\n\nSome larger datasets need to be installed separately, like senators and\nhouse_district_forecast. To install these, we recommend you install the\nfivethirtyeightdata package by running:\ninstall.packages('fivethirtyeightdata', repos =\n'https://fivethirtyeightdata.github.io/drat/', type = 'source')\n\n\n\ndata(bechdel)\nnew_bechdel &lt;- bechdel |&gt;\n  mutate(clean_test = factor(clean_test, c(\"nowomen\", \"notalk\", \"men\", \"dubious\", \"ok\"))) |&gt;\n  mutate(half_decades = cut(year, breaks = seq(1969, 2014, by = 5)))\n\n\nggplot(new_bechdel, aes(x = budget_2013, y = domgross_2013)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Movie Budget vs. Domestic Box Office Gross\", x = \"Movie Budget\", y = \"Domestic Box Office\")\n\n\n\nCreated by Madeleine Heafey",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-tri.html",
    "href": "bw/bw-tri.html",
    "title": "\n3  Trivariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking trivariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nlibrary(tidyverse)\nlibrary(mosaic)\nlibrary(fivethirtyeight)\n\n\ndata(\"Birthdays\")\ndaily_births &lt;- Birthdays |&gt; \n  group_by(date) |&gt; \n  summarize(births = sum(births)) |&gt; \n  mutate(year = year(date), \n         month = month(date, label = TRUE),\n         day_of_month = mday(date),\n         day_of_week = wday(date, label = TRUE))\n\n\nggplot(daily_births, aes(x = date, y = births, color = day_of_week)) +\n  geom_point(size = 0.75) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Daily Births Over Time and Day of Week\", color = \"Day of the Week\", y = \"# of Births\", x = \"Date\")\n\n\n\nCreated by Madeleine Heafey",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Trivariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-quad.html",
    "href": "bw/bw-quad.html",
    "title": "\n4  Quadvariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking quadvariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nlibrary(tidyverse)\nlibrary(mosaic)\nlibrary(fivethirtyeight)\nlibrary(ggplot2)\n\n\ndata(bechdel)\nnew_bechdel &lt;- bechdel |&gt;\n  mutate(clean_test = factor(clean_test, c(\"nowomen\", \"notalk\", \"men\", \"dubious\", \"ok\"))) |&gt;\n  mutate(half_decades = cut(year, breaks = seq(1969, 2014, by = 5)))\n\n\nggplot(new_bechdel, aes(x = half_decades, fill = clean_test)) +\n  geom_bar() +\n  labs(title = \"Number of Films Passing the Bechdel Test by Half Decade and Degree of Passing\", fill = \"Degree of Passing\", y = \"Number of Movies\", x = \"Half Decades\") +\n  facet_wrap(~binary)\n\n\n\nCreated by Madeleine Heafey",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quadvariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-spatial.html",
    "href": "bw/bw-spatial.html",
    "title": "\n5  Spatial Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking spatial visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\n# Load required libraries\nlibrary(tidyverse)\nlibrary(openintro)\nlibrary(mosaic)\nlibrary(maps)\nlibrary(leaflet)\nlibrary(ggplot2)\n\n\n# Import starbucks location data\nstarbucks &lt;- read.csv(\"https://mac-stat.github.io/data/starbucks.csv\")\n\n\nstarbucks_us_by_state &lt;- starbucks |&gt;\n  filter(Country == \"US\") |&gt;\n  count(State.Province) |&gt;\n  mutate(state_name = str_to_lower(abbr2state(State.Province)))\n\n\ncensus_pop_est_2018 &lt;- read_csv(\"https://mac-stat.github.io/data/us_census_2018_state_pop_est.csv\") |&gt;\n  separate(state, into = c(\"dot\", \"state\"), extra = \"merge\") |&gt;\n  select(-dot) |&gt;\n  mutate(state = str_to_lower(state))\n\nstarbucks_with_2018_pop_est &lt;-\n  starbucks_us_by_state |&gt;\n  left_join(census_pop_est_2018,\n    by = c(\"state_name\" = \"state\")\n  ) |&gt;\n  mutate(starbucks_per_10000 = (n / est_pop_2018) * 10000)\n\n\n#filtering for only Starbucks in contiguous US\nstarbucks_cma &lt;- starbucks |&gt; \n  filter(Country %in% c('US'), State.Province != \"AK\", State.Province != \"HI\")\n\n\nstates_map &lt;- map_data(\"state\")\n\n#creating choropleth map + points for each starbucks\nggplot(starbucks_with_2018_pop_est, aes(map_id = state_name, fill = starbucks_per_10000)) +\n  geom_map(map = states_map) +\n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    size = 0.3,\n    alpha = 0.2,\n    color = \"#09402c\",\n    inherit.aes = FALSE\n  ) +\n  scale_fill_gradient(low = \"white\", high = \"#006241\", name = \"Starbucks per 1000\") +\n  labs(title = \"Plot of Starbucks per 1000 people across contiguous US\") +\n  theme_map()\n\n\n\nCreated by Madeleine Heafey",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "bw/exam-01.html",
    "href": "bw/exam-01.html",
    "title": "\n6  Exam 1\n",
    "section": "",
    "text": "Grand research question: What does the consumption of each food category in each country look like?\n\n#9 tidyverse packages loaded\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\n\n#loads the tidytuesday data we need and stores it under \"fc\"\ntuesdata &lt;- tt_load('2020-02-18')\nfc &lt;- tuesdata$food_consumption\n\n\n#checking out the data\ndim(fc)\n\n[1] 1430    4\n\nstr(fc)\n\nspc_tbl_ [1,430 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ country      : chr [1:1430] \"Argentina\" \"Argentina\" \"Argentina\" \"Argentina\" ...\n $ food_category: chr [1:1430] \"Pork\" \"Poultry\" \"Beef\" \"Lamb & Goat\" ...\n $ consumption  : num [1:1430] 10.51 38.66 55.48 1.56 4.36 ...\n $ co2_emmission: num [1:1430] 37.2 41.53 1712 54.63 6.96 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   country = col_character(),\n  ..   food_category = col_character(),\n  ..   consumption = col_double(),\n  ..   co2_emmission = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nhead(fc)\n\n# A tibble: 6 × 4\n  country   food_category consumption co2_emmission\n  &lt;chr&gt;     &lt;chr&gt;               &lt;dbl&gt;         &lt;dbl&gt;\n1 Argentina Pork                10.5          37.2 \n2 Argentina Poultry             38.7          41.5 \n3 Argentina Beef                55.5        1712   \n4 Argentina Lamb & Goat          1.56         54.6 \n5 Argentina Fish                 4.36          6.96\n6 Argentina Eggs                11.4          10.5 \n\ntail(fc)\n\n# A tibble: 6 × 4\n  country    food_category            consumption co2_emmission\n  &lt;chr&gt;      &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n1 Bangladesh Eggs                            2.08          1.91\n2 Bangladesh Milk - inc. cheese             21.9          31.2 \n3 Bangladesh Wheat and Wheat Products       17.5           3.33\n4 Bangladesh Rice                          172.          220.  \n5 Bangladesh Soybeans                        0.61          0.27\n6 Bangladesh Nuts inc. Peanut Butter         0.72          1.27\n\n\n\n#the units of observation are food categories (by country), there are 11 food categories and 130 countries listed\nhead(fc, 22) \n\n# A tibble: 22 × 4\n   country   food_category            consumption co2_emmission\n   &lt;chr&gt;     &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n 1 Argentina Pork                           10.5          37.2 \n 2 Argentina Poultry                        38.7          41.5 \n 3 Argentina Beef                           55.5        1712   \n 4 Argentina Lamb & Goat                     1.56         54.6 \n 5 Argentina Fish                            4.36          6.96\n 6 Argentina Eggs                           11.4          10.5 \n 7 Argentina Milk - inc. cheese            195.          278.  \n 8 Argentina Wheat and Wheat Products      103.           19.7 \n 9 Argentina Rice                            8.77         11.2 \n10 Argentina Soybeans                        0             0   \n# ℹ 12 more rows\n\ntail(fc, 22)\n\n# A tibble: 22 × 4\n   country food_category            consumption co2_emmission\n   &lt;chr&gt;   &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n 1 Liberia Pork                            4.01         14.2 \n 2 Liberia Poultry                         8.91          9.57\n 3 Liberia Beef                            0.78         24.1 \n 4 Liberia Lamb & Goat                     0.48         16.8 \n 5 Liberia Fish                            4.13          6.59\n 6 Liberia Eggs                            2.05          1.88\n 7 Liberia Milk - inc. cheese              3.04          4.33\n 8 Liberia Wheat and Wheat Products       11.0           2.09\n 9 Liberia Rice                           94.8         121.  \n10 Liberia Soybeans                        0.63          0.28\n# ℹ 12 more rows\n\n\nUnderstanding the variables individually\n\n#density plot of consumption\nggplot(fc, aes(x = consumption)) +\n  geom_density()\n\n\n\n\n\n\n#density plot of co2 emission\nggplot(fc, aes(x = co2_emmission)) +\n  geom_density()\n\n\n\n\n\n\n\nUnderstanding consumption\n\n#box plot of consumption by food category\nfc |&gt;\n  mutate(food_category = recode(food_category, `Milk - inc. cheese` = \"Milk\", `Nuts inc. Peanut Butter` = \"Nuts\", `Wheat and Wheat Products` = \"Wheat\")) |&gt;\n  ggplot(aes(x = food_category, y = consumption)) +\n  geom_boxplot()\n\n\n\n\n\n\n#largely unhelpful point plot of overall food consumption by country\nfc |&gt;\n  group_by(country) |&gt;\n  summarize(total_consumption = sum(consumption)) |&gt;\n  ggplot(aes(x = country, y = total_consumption)) +\n  geom_point()\n\n\n\n\n\n\n\nAnswering grand RQ:\n\n#Creating dataset with countries that have highest consumption for each category and renaming some stuff to be shorter. I imagine there is a better way to do this.\nfc_highest &lt;- fc |&gt;\n  group_by(food_category) |&gt;\n  arrange(desc(consumption)) |&gt;\n  summarize(highest = max(consumption)) |&gt;\n  left_join(fc, join_by(highest == consumption)) |&gt;\n  select(`food_category.x`, highest, country)  |&gt;\n  mutate(country, country = recode(country, `Hong Kong SAR. China` = \"Hong Kong\", `Taiwan. ROC` = \"Taiwan\", `United Arab Emirates` = \"UAE\")) |&gt;\n  mutate(`food_category.x` = recode(`food_category.x`, `Milk - inc. cheese` = \"Milk\", `Nuts inc. Peanut Butter` = \"Nuts\", `Wheat and Wheat Products` = \"Wheat Products\"))\n\n#renaming fc to be shorter as well\nfc &lt;- fc |&gt;\n  mutate(food_category = recode(food_category, `Milk - inc. cheese` = \"Milk\", `Nuts inc. Peanut Butter` = \"Nuts\", `Wheat and Wheat Products` = \"Wheat Products\"))\n\n#Creating dot plot of consumption of each category of food where each dot is a different country. I labeled only the top country in each category because otherwise it would get too cluttered. The legend had to be removed entirely :/\nggplot(data = fc, aes(x = food_category, y = consumption, color = country)) +\n  geom_point() +\n  theme(legend.position = \"none\") +\n geom_text(data = fc_highest, aes(x = `food_category.x`, y = highest, label = country), nudge_y = 17) +\n  labs(title = \"Food Consumption per Capita (kg) By Country and Category\", x = \"Food category\", y = \"Consumption (kg)\")\n\n\n\nDot plot of food consumption per capita by category and country\n\n\n\nLooking at this dataset I wonder if there’s any way I could get a better look at the countries so they aren’t just all stacked on each other like they are currently. I also wish there was a version of the dataset with some more detailed categories so I could get a look at variations within them.\nAlternative graph that is by region for simplicity and clarity:\n\n#importing country mapping data from Andrada on Kaggle, the data was originally taken from lukes on GitHub\ncountry_data &lt;- read_csv(\"../data/continents2.csv\")\n\n#cutting down to only the columns I want\ncountry_data &lt;- country_data |&gt;\n  select(name, `alpha-2`, region)\n\n#joining country data to fc and resolving naming differences\nfc_regional &lt;- fc |&gt;\n  mutate(country, country = recode(country, USA = \"United States\", Swaziland = \"Eswatini\", `Hong Kong SAR. China` = \"Hong Kong\", `Bosnia and Herzegovina` = \"Bosnia And Herzegovina\", `Taiwan. ROC` = \"Taiwan\")) |&gt;\n  left_join(country_data, join_by(country == name)) |&gt;\n  mutate(food_category = recode(food_category, `Milk - inc. cheese` = \"Milk\", `Nuts inc. Peanut Butter` = \"Nuts\", `Wheat and Wheat Products` = \"Wheat Products\")) |&gt;\n  group_by(region, food_category) \n\nfc_regional |&gt;\n  summarize(region_consumption = sum(consumption)) |&gt;\n  ggplot(aes(x = food_category, y = region_consumption, color = region)) +\n  scale_color_brewer(palette = \"Set1\") +\n  geom_point(size = 1) +\n  labs(title = \"Total Regional Food Consumption (kg) by Category\", x = \"Category\", y = \"Consumption (kg)\", color = \"Region\")\n\n\n\nDot plot of food consumption by category and region\n\n\n\nSimilar to what I said with the first plot, I wish there was a version of the dataset with some more detailed categories so I could get a look at variations within them. I also think that it would be nice to make some plots with sub-regions, since just going off continents is probably erasing a lot of variation here.",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Exam 1</span>"
    ]
  },
  {
    "objectID": "bw/exam-02.html",
    "href": "bw/exam-02.html",
    "title": "\n7  Exam 2\n",
    "section": "",
    "text": "#loading packages\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rnaturalearth)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n#loading data\ntuesdata &lt;- tt_load('2020-02-18')\n\n---- Compiling #TidyTuesday Information for 2020-02-18 ----\n--- There is 1 file available ---\n\n\n── Downloading files ───────────────────────────────────────────────────────────\n\n  1 of 1: \"food_consumption.csv\"\n\nfc &lt;- tuesdata$food_consumption\n\n#inspect data\nstr(fc)\n\nspc_tbl_ [1,430 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ country      : chr [1:1430] \"Argentina\" \"Argentina\" \"Argentina\" \"Argentina\" ...\n $ food_category: chr [1:1430] \"Pork\" \"Poultry\" \"Beef\" \"Lamb & Goat\" ...\n $ consumption  : num [1:1430] 10.51 38.66 55.48 1.56 4.36 ...\n $ co2_emmission: num [1:1430] 37.2 41.53 1712 54.63 6.96 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   country = col_character(),\n  ..   food_category = col_character(),\n  ..   consumption = col_double(),\n  ..   co2_emmission = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nhead(fc, 22)\n\n# A tibble: 22 × 4\n   country   food_category            consumption co2_emmission\n   &lt;chr&gt;     &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n 1 Argentina Pork                           10.5          37.2 \n 2 Argentina Poultry                        38.7          41.5 \n 3 Argentina Beef                           55.5        1712   \n 4 Argentina Lamb & Goat                     1.56         54.6 \n 5 Argentina Fish                            4.36          6.96\n 6 Argentina Eggs                           11.4          10.5 \n 7 Argentina Milk - inc. cheese            195.          278.  \n 8 Argentina Wheat and Wheat Products      103.           19.7 \n 9 Argentina Rice                            8.77         11.2 \n10 Argentina Soybeans                        0             0   \n# ℹ 12 more rows\n\n\n\n#inspect country variable\nfc |&gt;\n  distinct(country) |&gt;\n  summarize(country_count = n())\n\n# A tibble: 1 × 1\n  country_count\n          &lt;int&gt;\n1           130\n\n#inspect food_category variable\nfc |&gt;\n  distinct(food_category)\n\n# A tibble: 11 × 1\n   food_category           \n   &lt;chr&gt;                   \n 1 Pork                    \n 2 Poultry                 \n 3 Beef                    \n 4 Lamb & Goat             \n 5 Fish                    \n 6 Eggs                    \n 7 Milk - inc. cheese      \n 8 Wheat and Wheat Products\n 9 Rice                    \n10 Soybeans                \n11 Nuts inc. Peanut Butter \n\n#cleaning up some value names in food_category\nfcc &lt;- fc |&gt;\n  mutate(food_category = fct_recode(food_category, \n                                    \"Lamb\" = \"Lamb & Goat\", \n                                    \"Dairy\" = \"Milk - inc. cheese\", \n                                    \"Wheat\" = \"Wheat and Wheat Products\", \n                                    \"Nuts\" = \"Nuts inc. Peanut Butter\"))\n\n#re-inspect food_category variable\nfcc |&gt;\n  distinct(food_category)\n\n# A tibble: 11 × 1\n   food_category\n   &lt;fct&gt;        \n 1 Pork         \n 2 Poultry      \n 3 Beef         \n 4 Lamb         \n 5 Fish         \n 6 Eggs         \n 7 Dairy        \n 8 Wheat        \n 9 Rice         \n10 Soybeans     \n11 Nuts         \n\n#looks good!\n\n\n#finding the 5 countries that produce the most food\nfcc |&gt;\n  group_by(country) |&gt;\n  summarize(total_consumption = sum(consumption)) |&gt;\n  arrange(desc(total_consumption)) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n  country     total_consumption\n  &lt;chr&gt;                   &lt;dbl&gt;\n1 Finland                  640.\n2 Lithuania                555.\n3 Sweden                   550 \n4 Netherlands              534.\n5 Albania                  533.\n\n#this could be visualized most appropriately with a bar plot\n\n\n#finding the top 5 consuming countries for each food category\nfcc |&gt;\n  group_by(food_category) |&gt;\n  slice_max(consumption, n = 5)\n\n# A tibble: 55 × 4\n# Groups:   food_category [11]\n   country   food_category consumption co2_emmission\n   &lt;chr&gt;     &lt;fct&gt;               &lt;dbl&gt;         &lt;dbl&gt;\n 1 Argentina Beef                 55.5        1712  \n 2 Brazil    Beef                 39.2        1211. \n 3 USA       Beef                 36.2        1118. \n 4 Australia Beef                 33.9        1045. \n 5 Bermuda   Beef                 33.2        1023. \n 6 Japan     Eggs                 19.2          17.6\n 7 Paraguay  Eggs                 18.8          17.3\n 8 China     Eggs                 18.8          17.2\n 9 Mexico    Eggs                 18.3          16.8\n10 Ukraine   Eggs                 18.0          16.5\n# ℹ 45 more rows\n\n#this could be best visualized with a box plot\n\n\n#viz attempt 1\nne_countries(returnclass = \"sf\") |&gt;\n  select(name, geometry) |&gt;\n  left_join(fcc |&gt; select(-co2_emmission),\n            join_by(name == country)) |&gt;\n  ggplot() +\n  geom_sf(aes(fill = consumption)) +\n  facet_wrap(~food_category) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nmap_data &lt;- ne_countries(returnclass = \"sf\") |&gt;\n  select(name, geometry) |&gt;\n  left_join(fcc |&gt; select(-co2_emmission),\n            join_by(name == country))\n\n#problems this viz suffers from:\n# missing countries\n# unclear color scale\n# hard to read\n# too small, too much going on\n# no real logic to its layout\n\n#list of countries with missing consumption data\nmap_data |&gt;\n  filter(is.na(consumption)) |&gt;\n  st_drop_geometry() |&gt;\n  select(name) |&gt;\n  arrange(name)\n\n                       name\n1               Afghanistan\n2                Antarctica\n3                Azerbaijan\n4                     Benin\n5                    Bhutan\n6          Bosnia and Herz.\n7                    Brunei\n8              Burkina Faso\n9                   Burundi\n10     Central African Rep.\n11                     Chad\n12                  Czechia\n13            Côte d'Ivoire\n14          Dem. Rep. Congo\n15                 Djibouti\n16           Dominican Rep.\n17               Eq. Guinea\n18                  Eritrea\n19             Falkland Is.\n20   Fr. S. Antarctic Lands\n21                    Gabon\n22                Greenland\n23            Guinea-Bissau\n24                   Guyana\n25                    Haiti\n26                     Iraq\n27                   Kosovo\n28               Kyrgyzstan\n29                     Laos\n30                  Lebanon\n31                  Lesotho\n32                    Libya\n33                     Mali\n34               Mauritania\n35                  Moldova\n36                 Mongolia\n37               Montenegro\n38                N. Cyprus\n39              North Korea\n40          North Macedonia\n41                Palestine\n42         Papua New Guinea\n43              Puerto Rico\n44                    Qatar\n45                 S. Sudan\n46              Solomon Is.\n47                  Somalia\n48               Somaliland\n49                    Sudan\n50                 Suriname\n51                    Syria\n52                   Taiwan\n53               Tajikistan\n54              Timor-Leste\n55             Turkmenistan\n56 United States of America\n57               Uzbekistan\n58                  Vanuatu\n59                W. Sahara\n60                    Yemen\n61                 eSwatini\n\n\n\n#viz attempt 2\nne_countries(returnclass = \"sf\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = ifelse(name == \"United States of America\", \"USA\", name)) |&gt;\n  mutate(name = ifelse(name == \"Bosnia and Herz.\", \"Bosnia andd Herzegovina\", name)) |&gt;\n  mutate(name = ifelse(name == \"Czechia\", \"Czech Republic\", name)) |&gt;\n  mutate(name = ifelse(name == \"Taiwan\", \"Taiwan. ROC\", name)) |&gt;\n  left_join(fcc |&gt; select(-co2_emmission),\n            join_by(name == country)) |&gt;\n  pivot_wider(names_from = food_category,\n              values_from = consumption) |&gt;\n  select(-\"NA\") |&gt;\n  pivot_longer(cols = c(-name, -geometry),\n               names_to = \"food_category\",\n               values_to = \"consumption\") |&gt;\n  ggplot() +\n  geom_sf(aes(fill = consumption)) +\n  facet_wrap(~food_category) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n#problems this viz suffers from:\n# still has an unclear color scale\n# hard to read\n# small\n# order still isn't logical\n\n#min, max, range of consumption for each food. The values are slightly different from those in the handout but it's just rounding\nfcc |&gt;\n  group_by(food_category) |&gt;\n  summarize(min = min(consumption),\n            max = max(consumption),\n            range = max - min) |&gt;\n  arrange(desc(range))\n\n# A tibble: 11 × 4\n   food_category   min   max range\n   &lt;fct&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Dairy          3.04 431.  428. \n 2 Wheat          2.74 198.  195. \n 3 Fish           0.24 180.  179. \n 4 Rice           0.95 172.  171. \n 5 Pork           0     67.1  67.1\n 6 Poultry        0.47  62.5  62.0\n 7 Beef           0.78  55.5  54.7\n 8 Nuts           0.18  23.0  22.8\n 9 Lamb           0     21.1  21.1\n10 Eggs           0.16  19.2  19.0\n11 Soybeans       0     17.0  17.0\n\n\n\n#viz attempt 3\nne_countries(returnclass = \"sf\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = ifelse(name == \"United States of America\", \"USA\", name)) |&gt;\n  mutate(name = ifelse(name == \"Bosnia and Herz.\", \"Bosnia and Herzegovina\", name)) |&gt;\n  mutate(name = ifelse(name == \"Czechia\", \"Czech Republic\", name)) |&gt;\n  mutate(name = ifelse(name == \"Taiwan\", \"Taiwan. ROC\", name)) |&gt;\n  left_join(\n    fcc |&gt;\n      select(-co2_emmission) |&gt;\n      group_by(food_category) |&gt;\n      mutate(consumption = (consumption - mean(consumption))/sd(consumption)),\n    join_by(name == country)) |&gt;\n  pivot_wider(names_from = food_category, values_from = consumption) |&gt;\n  select(-\"NA\") |&gt;\n  pivot_longer(cols = c(-name, -geometry),\n               names_to = \"food_category\",\n               values_to = \"consumption\") |&gt;\n  ggplot() +\n  geom_sf(aes(fill = consumption)) +\n  facet_wrap(~food_category) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n#this viz could be enhanced by making the colors clearer and maybe the viz as a whole bigger\n\n\n#final version of graph scaled up with some slightly clearer colors\nne_countries(returnclass = \"sf\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = ifelse(name == \"United States of America\", \"USA\", name)) |&gt;\n  mutate(name = ifelse(name == \"Bosnia and Herz.\", \"Bosnia and Herzegovina\", name)) |&gt;\n  mutate(name = ifelse(name == \"Czechia\", \"Czech Republic\", name)) |&gt;\n  mutate(name = ifelse(name == \"Taiwan\", \"Taiwan. ROC\", name)) |&gt;\n  left_join(\n    fcc |&gt;\n      select(-co2_emmission) |&gt;\n      group_by(food_category) |&gt;\n      mutate(consumption = (consumption - mean(consumption))/sd(consumption)),\n    join_by(name == country)) |&gt;\n  pivot_wider(names_from = food_category, values_from = consumption) |&gt;\n  select(-\"NA\") |&gt;\n  pivot_longer(cols = c(-name, -geometry),\n               names_to = \"food_category\",\n               values_to = \"consumption\") |&gt;\n  ggplot() +\n  geom_sf(aes(fill = consumption)) +\n  scale_fill_continuous(low=\"#fffcad\", high=\"#ff0000\", na.value=\"transparent\") +\n  facet_wrap(~food_category, ncol = 2) +\n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Exam 2</span>"
    ]
  },
  {
    "objectID": "bw/Solo-Project.html",
    "href": "bw/Solo-Project.html",
    "title": "\n8  Solo Project\n",
    "section": "",
    "text": "#loading packages\nlibrary(leaflet)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(mosaic)\nlibrary(patchwork)\n\n#importing korea shapefile from data folder, taken from simplemaps.com\nkorea_map &lt;- st_read(\"../data/kr_shp\")\n\nReading layer `kr' from data source \n  `/Users/madeleine/Documents/GitHub/portfolio-mheafey/data/kr_shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 17 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 124.6136 ymin: 33.19758 xmax: 130.9207 ymax: 38.62434\nGeodetic CRS:  WGS 84\n\n#importing demographic data, taken from Alex on Kaggle\nkorea_data &lt;- read_csv(\"../data/Korean_demographics_2000-2022.csv\")\n\n\n#Clearing up region naming differences. One dataset uses the Korean province names, the other one uses the English ones. I chose to stick with the English names for clarity.\nkorea_data &lt;- korea_data |&gt;\n  mutate(Region, Region = recode(Region, \n                                 `Chungcheongbuk-do` = \"North Chungcheong\",\n                                 `Chungcheongnam-do` = \"South Chungcheong\",\n                                 `Gangwon-do` = \"Gangwon\",\n                                 `Gyeonggi-do` = \"Gyeonggi\",\n                                 `Gyeongsangbuk-do` = \"North Gyeongsang\",\n                                 `Gyeongsangnam-do` = \"South Gyeongsang\",\n                                 `Jeollabuk-do` = \"North Jeolla\",\n                                 `Jeollanam-do` = \"South Jeolla\"))\n\n#joining the datasets\nkorea_complete &lt;- korea_map |&gt;\n  left_join(korea_data, join_by(name == Region))\n\n\n#Birth rate map for 2000\nmap_1 &lt;- korea_complete |&gt;\n  filter(Date == \"1/1/2000\") |&gt;\n  ggplot() +\n  geom_sf(aes(fill = Birth_rate)) +\n  scale_fill_gradient(low = \"#fff799\", high = \"#2600ff\", limits = c(4, 20), na.value=\"white\", guide = \"none\") +\n  labs(caption = \"2000\") +\n  theme_void()\n\n#Birth rate map for 2021\nmap_2 &lt;- korea_complete |&gt;\n  filter(Date == \"9/1/2021\") |&gt;\n  ggplot() +\n  geom_sf(aes(fill = Birth_rate)) +\n  scale_fill_gradient(low = \"#fff799\", high = \"#2600ff\", limits = c(4, 20), breaks = c(5, 10, 15, 19)) +\n  labs(fill = \"Birth Rate\", caption = \"2021\") +\n  theme_void()\n\n#placing the two maps side by side + adding title\nmap_1 + map_2 + plot_annotation(title = \"Korean Birth Rate (per 1000) by Region, 2000 to 2021\")\n\n\n\nCreated by Madeleine Heafey\n\n\n\nThe declining birth rate has been the topic of much discussion in South Korea in recent years. The dataset I used only goes as far back as the year 2000 (so after the decline had already begun), but the viewer can still get a good picture of just how dramatic the change is— the highest values from the 2021 graph are still lower than the lowest values from 2000. Still, these two graphs give us a little bit more insight into how this decline is spread spatially, and reveal some interesting points.\nMost notably, the city of Sejong (in the center-Western region) has no data at all from 2000 and yet has by far the highest birth rate in 2021. While this might appear at first to be the result of just another gap in our dataset, the reality is that Sejong did not exist until 2007. The city was conceived of as a new administrative capital for South Korea, and as such has a much higher concentration of government jobs than the other regions of the country. Government jobs are more stable, and government workers have much more freedom than private sector workers when it comes to maternity and other types of childcare leave, making it easier for them to raise children. Sejong also has much better childcare infrastructure and lower housing costs than other Korean cities.  1 \nOne other insight from this graph is the fact that, for the most part, the decline in birth rates doesn’t seem particularly regional at all. Though in 2000 there are noticeable regional differences in birth rates, in 2000 they are (with the exception of Sejong) all similarly low. This suggests that the reasons for the low Korean birth rate go beyond just regional factors like city costs of living or regional infrastructure and points to the existence of broader issues facing the country as a whole.\n 1. source :) (https://www.koreatimes.co.kr/southkorea/society/20211104/whats-behind-sejong-citys-high-birthrate)",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Solo Project</span>"
    ]
  },
  {
    "objectID": "ica/introduction.html",
    "href": "ica/introduction.html",
    "title": "10  Introduction",
    "section": "",
    "text": "Exercise 1: RStudio\nLaunch RStudio. Notice that there are four panes, each serving a different purpose. Today, we’ll work within the **console** and will *not* save any work.\n```{r fig-main, fig.cap=“RStudio Interface”} #| echo: false\nknitr::include_graphics(“../images/RStudioImage.jpg”) ```",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "ica/introduction.html#solutions",
    "href": "ica/introduction.html#solutions",
    "title": "10  Introduction",
    "section": "16.1 Solutions",
    "text": "16.1 Solutions\n&lt;details&gt;\n&lt;summary&gt;Click for Solutions&lt;/summary&gt;\n\nExercise 2: Concole\n```{r} 4 + 2 4/2 4^2 4*2 ```\n```{r} #| eval: false",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "ica/quarto-demo.html",
    "href": "ica/quarto-demo.html",
    "title": "\n11  My first Quarto document\n",
    "section": "",
    "text": "12 Intro\nMacalester College is in the Twin Cities. It has:\n\nfour seasons\nbagpipes\ndelightful students\n\nCheck it out for yourself:\n\n\n\n13 Exercise 1: Deduce Quarto features\nCheck out the appearance and contents of this document. Thoughts?\nIn the toolbar at the top of this document, Render the .qmd file into a .html file. Where is this file stored?\nIn the ica folder (same folder as this document)\nThoughts about its appearance / contents?\nCan you edit it?\nToggling between the .qmd and .html files, explain the purpose of the following features in the .qmd file:\n* Italics\n** Bold\n# Creates headers\n- Creates list items\n\\ Creates line breaks\n![](url) Embeds a url\n\n\n14 Exercise 2: Code\nHow does this appear in the .qmd? The .html? So…?!\nseq(from = 100, to = 1000, by = 50)\n\n\n15 Exercise 3: Chunks\nQuarto isn’t a mind reader – we must distinguish R code from text. We do so by putting code inside an R chunk:\n\nseq()\n\n[1] 1\n\n\n\nPut the seq() code in the chunk.\nPress the green arrow in the top right of the chunk. What happens in the qmd?\nRender. What appears in the html: R code, output, or both?\n\n\n\n16 Exercise 4: Practice\n\nUse R code to create the following sequence: 10 10 10 10\nStore the sequence as four_tens.\nUse an R function (which we haven’t learned!) to add up the numbers in four_tens.\n\n\nrep(10, 4)\n\n[1] 10 10 10 10\n\nfour_tens &lt;- rep(10, 4)\nsum(four_tens)\n\n[1] 40\n\n\n\n\n17 Exercise 5: Fix this code\nCode is a form of communication, and the code below doesn’t cut it.\nPut the code in a chunk and fix it.\n\nrep(x = 1, times = 10) \n\n [1] 1 1 1 1 1 1 1 1 1 1\n\nseq(from = 100, to = 1000, length = 20) \n\n [1]  100.0000  147.3684  194.7368  242.1053  289.4737  336.8421  384.2105\n [8]  431.5789  478.9474  526.3158  573.6842  621.0526  668.4211  715.7895\n[15]  763.1579  810.5263  857.8947  905.2632  952.6316 1000.0000\n\nstudent_count &lt;- 27\n\n\n\n18 Exercise 6: Comments\nRun the chunk below. Notice that R ignores anything in a line starting with a pound sign (#). If we took the # away we’d get an error!\n\n# This is a comment\n4 + 5\n\n[1] 9\n\n\nWe’ll utilize this feature to comment our code, i.e. leave short notes about what our code is doing. Below, replace the ??? with an appropriate comment.\n\n# defining temperature_c and temperature_f in terms of temperature_c\ntemperature_c &lt;- 10\ntemperature_f &lt;- temperature_c * 9/5 + 32\ntemperature_f\n\n[1] 50",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>My first Quarto document</span>"
    ]
  },
  {
    "objectID": "ica/ica-uni.html",
    "href": "ica/ica-uni.html",
    "title": "\n12  Univariate Viz\n",
    "section": "",
    "text": "12.1 Exercises\n# Import data\nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")\n\nlibrary(ggplot2)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-uni.html#exercises",
    "href": "ica/ica-uni.html#exercises",
    "title": "\n12  Univariate Viz\n",
    "section": "",
    "text": "Exercise 1: Research Questions\nLet’s dig into the hikes data, starting with the elevation and difficulty ratings of the hikes:\n\nhead(hikes)\n\n             peak elevation difficulty ascent length time    rating\n1     Mt. Marcy        5344          5   3166   14.8 10.0  moderate\n2 Algonquin Peak       5114          5   2936    9.6  9.0  moderate\n3   Mt. Haystack       4960          7   3570   17.8 12.0 difficult\n4   Mt. Skylight       4926          7   4265   17.9 15.0 difficult\n5 Whiteface Mtn.       4867          4   2535   10.4  8.5      easy\n6       Dix Mtn.       4857          5   2800   13.2 10.0  moderate\n\n\n\nWhat features would we like a visualization of the categorical difficulty rating variable to capture? #The relative frequency of the different difficulties\nWhat about a visualization of the quantitative elevation variable? #Some kind of visual comparison between their values\nExercise 2: Load tidyverse\nWe’ll address the above questions using ggplot tools. Try running the following chunk and simply take note of the error message – this is one you’ll get a lot!\n\n# Use the ggplot function\nggplot(hikes, aes(x = rating))\n\n\n\n\n\n\n\nIn order to use ggplot tools, we have to first load the tidyverse package in which they live. We’ve installed the package but we need to tell R when we want to use it. Run the chunk below to load the library. You’ll need to do this within any .qmd file that uses ggplot().\n\n# Load the package\nlibrary(tidyverse)\n\nExercise 3: Bar Chart of Ratings - Part 1\nConsider some specific research questions about the difficulty rating of the hikes:\n\nHow many hikes fall into each category?\nAre the hikes evenly distributed among these categories, or are some more common than others?\n\nAll of these questions can be answered with: (1) a bar chart; of (2) the categorical data recorded in the rating column. First, set up the plotting frame:\n\nggplot(hikes, aes(x = rating))\n\n\n\n\n\n\n\nThink about:\n\nWhat did this do? What do you observe?\n\nggplot created a blank chart\n\nWhat, in general, is the first argument of the ggplot() function?\n\nthe name of the data\n\nWhat is the purpose of writing x = rating?\n\nto specify which variable we want to work with\n\nWhat do you think aes stands for?!?\n\naesthetic\nExercise 4: Bar Chart of Ratings - Part 2\nNow let’s add a geometric layer to the frame / canvas, and start customizing the plot’s theme. To this end, try each chunk below, one by one. In each chunk, make a comment about how both the code and the corresponding plot both changed.\nNOTE:\n\nPay attention to the general code properties and structure, not memorization.\nNot all of these are “good” plots. We’re just exploring ggplot.\n\n\n# The plot now has a coordinate system and the data is visible\nggplot(hikes, aes(x = rating)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n# The axes have labels now\nggplot(hikes, aes(x = rating)) +\n  geom_bar() +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# The bars are now blue!\nggplot(hikes, aes(x = rating)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# The bars are now blue with an orange outline\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# The background color of the plot has been changed\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\")  +\n  labs(x = \"Rating\", y = \"Number of hikes\") +\n  theme_minimal()\n\n\n\n\n\n\n\nExercise 5: Bar Chart Follow-up\nPart a\nReflect on the ggplot() code.\n\nWhat’s the purpose of the +? When do we use it?\n\nWe use it to add more features to the plots\n\nWe added the bars using geom_bar()? Why “geom”?\n\nBecause the bars are geometric elements we are adding\n\nWhat does labs() stand for?\n\nLabels\n\nWhat’s the difference between color and fill?\n\nColor changes the outline color, fill changes the fill color\nPart b\nIn general, bar charts allow us to examine the following properties of a categorical variable:\n\n\nobserved categories: What categories did we observe? # Difficulty of the hikes\n\nvariability between categories: Are observations evenly spread out among the categories, or are some categories more common than others? # Moderate is more common than Easy or Difficult\n\nWe must then translate this information into the context of our analysis, here hikes in the Adirondacks. Summarize below what you learned from the bar chart, in context.\nPart c\nIs there anything you don’t like about this barplot? For example: check out the x-axis again.\nEasy, Moderate, and Difficult are not in a logical order\nExercise 6: Sad Bar Chart\nLet’s now consider some research questions related to the quantitative elevation variable:\n\nAmong the hikes, what’s the range of elevation and how are the hikes distributed within this range (e.g. evenly, in clumps, “normally”)?\nWhat’s a typical elevation?\nAre there any outliers, i.e. hikes that have unusually high or low elevations?\n\nHere:\n\nConstruct a bar chart of the quantitative elevation variable.\nExplain why this might not be an effective visualization for this and other quantitative variables. (What questions does / doesn’t it help answer?)\n\n\n#This is not an effective visualization for the elevation variable since it doesn't give a good sense of distribution or outliers\n\nggplot(hikes, aes(x = elevation)) +\n  geom_bar()\n\n\n\n\n\n\n\nExercise 7: A Histogram of Elevation\nQuantitative variables require different viz than categorical variables. Especially when there are many possible outcomes of the quantitative variable. It’s typically insufficient to simply count up the number of times we’ve observed a particular outcome as the bar graph did above. It gives us a sense of ranges and typical outcomes, but not a good sense of how the observations are distributed across this range. We’ll explore two methods for graphing quantitative variables: histograms and density plots.\nHistograms are constructed by (1) dividing up the observed range of the variable into ‘bins’ of equal width; and (2) counting up the number of cases that fall into each bin. Check out the example below:\n\nPart a\nLet’s dig into some details.\n\nHow many hikes have an elevation between 4500 and 4700 feet?\n\n6 hikes\n\nHow many total hikes have an elevation of at least 5100 feet?\n\n4 hikes\nPart b\nNow the bigger picture. In general, histograms allow us to examine the following properties of a quantitative variable:\n\n\ntypical outcome: Where’s the center of the data points? What’s typical?\n\nvariability & range: How spread out are the outcomes? What are the max and min outcomes?\n\nshape: How are values distributed along the observed range? Is the distribution symmetric, right-skewed, left-skewed, bi-modal, or uniform (flat)?\n\noutliers: Are there any outliers, i.e. outcomes that are unusually large/small?\n\nWe must then translate this information into the context of our analysis, here hikes in the Adirondacks. Addressing each of the features in the above list, summarize below what you learned from the histogram, in context.\nWe learned that the histogram is skewed right, with the center of the data points being clummped around 4400 feet. The minimum is 3700 feet and the maximum is 5500 feet. There are no outliers.\nExercise 8: Building Histograms - Part 1\n2-MINUTE CHALLENGE: Thinking of the bar chart code, try to intuit what line you can tack on to the below frame of elevation to add a histogram layer. Don’t forget a +. If it doesn’t come to you within 2 minutes, no problem – all will be revealed in the next exercise.\n\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nExercise 9: Building Histograms - Part 2\nLet’s build some histograms. Try each chunk below, one by one. In each chunk, make a comment about how both the code and the corresponding plot both changed.\n\n# A histogram of the elevation data was created\n\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n# The bars now have a white outline\n\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n# The bars now have a blue fill\n\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", fill = \"blue\") \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n# The bars no longer have a blue fill and the axis labels have been clarified\n\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n# The bin size has been made way bigger\n\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 1000) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# The bin size has been made way smaller\n\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 5) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\n# The bin size is now normal (200)\n\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 200) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\nExercise 10: Histogram Follow-up\n\nWhat function added the histogram layer / geometry?\n\ngeom_histogram()\n\nWhat’s the difference between color and fill?\n\ncolor changes the outline color, while fill changes the fill color\n\nWhy does adding color = \"white\" improve the visualization?\n\nIt makes the bars pop more!\n\nWhat did binwidth do?\n\nChanges the width of the bin\n\nWhy does the histogram become ineffective if the binwidth is too big (e.g. 1000 feet)?\n\nIt becomes impossible to see any meaningful trends in the data\n\nWhy does the histogram become ineffective if the binwidth is too small (e.g. 5 feet)?\n\nIt’s still impossible to see any meaningful trends in the data\nExercise 11: Density Plots\nDensity plots are essentially smooth versions of the histogram. Instead of sorting observations into discrete bins, the “density” of observations is calculated across the entire range of outcomes. The greater the number of observations, the greater the density! The density is then scaled so that the area under the density curve always equals 1 and the area under any fraction of the curve represents the fraction of cases that lie in that range.\nCheck out a density plot of elevation. Notice that the y-axis (density) has no contextual interpretation – it’s a relative measure. The higher the density, the more common are elevations in that range.\n\nggplot(hikes, aes(x = elevation)) +\n  geom_density()\n\n\n\n\n\n\n\nQuestions\n\n\nINTUITION CHECK: Before tweaking the code and thinking back to geom_bar() and geom_histogram(), how do you anticipate the following code will change the plot?\n\ngeom_density(color = \"blue\")\n\nThis will probably turn the line blue\n\ngeom_density(fill = \"orange\")\n\nThis will probably turn the area under the line orange\n\nTRY IT! Test out those lines in the chunk below. Was your intuition correct?\n\n\nggplot(hikes, aes(x = elevation)) +\n  geom_density(color = \"blue\", fill = \"orange\")\n\n\n\n\n\n\n#yes!\n\n\nExamine the density plot. How does it compare to the histogram? What does it tell you about the typical elevation, variability / range in elevations, and shape of the distribution of elevations within this range?\n\nIt gives us a better sense of the variability and shape of elevations since the data isn’t sorted into bins like in the histogram.\nExercise 12: Density Plots vs Histograms\nThe histogram and density plot both allow us to visualize the behavior of a quantitative variable: typical outcome, variability / range, shape, and outliers. What are the pros/cons of each? What do you like/not like about each?\n\nSince the histogram is sorted into bins it’s easy to get a sense of how much data is in any specific range, but the shape of the data can be unclear depending on the size of the bins.\nThe density plot gives a really good picture of the distribution of the data, but it’s hard to see exactly how many data points there are at a certain elevation or any outliers.\nExercise 13: Code = communication\nWe obviously won’t be done until we talk about communication. All code above has a similar general structure (where the details can change):\n\nggplot(___, aes(x = ___)) + \n  geom___(color = \"___\", fill = \"___\") + \n  labs(x = \"___\", y = \"___\")\n\n\nThough not necessary to the code working, it’s common, good practice to indent or tab the lines of code after the first line (counterexample below). Why?\nIt makes the code a lot more readable, since it’s clear that the ggplot is the thing being modified\n\n\n# YUCK\nggplot(hikes, aes(x = elevation)) +\ngeom_histogram(color = \"white\", binwidth = 200) +\nlabs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\nThough not necessary to the code working, it’s common, good practice to put a line break after each + (counterexample below). Why?\nIt breaks up the modifications to make it easir to see what’s happening to the plot\n\n\n# YUCK \nggplot(hikes, aes(x = elevation)) + geom_histogram(color = \"white\", binwidth = 200) + labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\nExercise 14: Practice\nPart a\nPractice your viz skills to learn about some of the variables in one of the following datasets from the previous class:\n\n# Data on students in this class\nsurvey &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/survey.csv\")\n\nggplot(survey, aes(x = minutes_to_campus)) + \n  geom_density() + \n  labs(x = \"Minutes to campus\")\n\n\n\n\n\n\nggplot(survey, aes(x = minutes_to_campus)) +\n  geom_histogram(color = \"white\", fill = \"black\", binwidth = 2) +\n  labs(x = \"Minutes to campus\", y = \"Number of students\")\n\n\n\n\n\n\n# World Cup data\nworld_cup &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-29/worldcups.csv\")\n\nggplot(world_cup, aes(x = attendance)) + \n  geom_density() + \n  labs(x = \"Attendance\")\n\n\n\n\n\n\nggplot(world_cup, aes(x = attendance)) +\n  geom_histogram(color = \"white\", fill = \"black\", binwidth = 250000) +\n  labs(x = \"Game attendance\", y = \"Number of games\")\n\n\n\n\n\n\n\nPart b\nCheck out the RStudio Data Visualization cheat sheet to learn more features of ggplot.\n\n\n\n\n\n\nCheck → Commit → Push\n\n\n\nWhen done, don’t forgot to click Render Book and check the resulting HTML files. If happy, jump to GitHub Desktop and commit the changes with the message Finish activity 3 and push to GitHub. Wait few seconds, then visit your portfolio website and make sure the changes are there.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-uni.html#solutions",
    "href": "ica/ica-uni.html#solutions",
    "title": "\n12  Univariate Viz\n",
    "section": "\n12.2 Solutions",
    "text": "12.2 Solutions\n\nClick for Solutions\nExercise 1: Research Questions\n\nFor example: how many hikes are there in each category? are any categories more common than others?\nFor example: What’s a typical elevation? What’s the range in elevations?\nExercise 3: Bar Chart of Ratings - Part 1\n\nggplot(hikes, aes(x = rating))\n\n\n\n\n\n\n\n\njust a blank canvas\nname of the dataset\nindicate which variable to plot on x-axis\n\naesthetics\nExercise 4: Bar Chart of Ratings - Part 2\n\n# Add a bar plot LAYER\nggplot(hikes, aes(x = rating)) +\n  geom_bar()\n\n\n\n\n\n\n# Add meaningful axis labels\nggplot(hikes, aes(x = rating)) +\n  geom_bar() +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n# FILL the bars with blue\nggplot(hikes, aes(x = rating)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n# COLOR the outline of the bars in orange\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n# Change the theme to a white background\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\")  +\n  labs(x = \"Rating\", y = \"Number of hikes\") + \n  theme_minimal()\n\n\n\n\n\n\n\nExercise 5: Bar Chart Follow-up\nPart a\n\nTo indicate we’re still adding layers to / modifying our plot.\nBars are the geometric elements we’re adding in this layer.\nlabels\n\nfill fills in the bars. color outlines the bars.\nPart b\nMost hikes are moderate, the fewest number are difficult.\nPart c\nI don’t like that the categories are alphabetical, not in order of difficulty level.\nExercise 6: Sad Bar Chart\nThere are too many different outcomes of elevation.\n\nggplot(hikes, aes(x = elevation)) + \n  geom_bar()\n\n\n\n\n\n\n\nExercise 7: A Histogram of Elevation\nPart a\n\n6\n1 + 1 = 2\nPart b\nElevations range from roughly 3700 to 5500 feet. Elevations vary from hike to hike relatively normally (with a bell shape) around a typical elevation of roughly 4500 feet.\nExercise 9: Building Histograms - Part 2\n\n# Add a histogram layer\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n# Outline the bars in white\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n# Fill the bars in blue\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", fill = \"blue\") \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n# Add axis labels\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n# Change the width of the bins to 1000 feet\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 1000) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n# Change the width of the bins to 5 feet\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 5) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n# Change the width of the bins to 200 feet\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 200) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\nExercise 10: Histogram Follow-up\n\ngeom_histogram()\n\ncolor outlined the bars and fill filled them\neasier to distinguish between the bars\nchanged the bin width\nwe lump too many hikes together and lose track of the nuances\nwe don’t lump enough hikes together and lose track of the bigger picture trends\nExercise 11: Density plots\n\nggplot(hikes, aes(x = elevation)) +\n geom_density(color = \"blue\", fill = \"orange\")\n\n\n\n\n\n\n\nExercise 13: Code = Communication\n\nClarifies that the subsequent lines are a continuation of the first. That is, we’re not done with the plot yet. These lines are all part of the same idea.\nThis is like a run-on sentence. It’s tough to track the distinct steps that go into building the plot.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html",
    "href": "ica/ica-bi.html",
    "title": "\n13  Bivariate Viz\n",
    "section": "",
    "text": "13.1 Exercises (required)\nGithub user Tony McGovern has compiled and made available 2020/2016/2012 presidential election results for most of 3000+ U.S. counties, except Alaska. (Image: Wikimedia Commons)\nA wrangled version of this data, is imported below, after being combined with:\n# Load data\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n# Check it out\nhead(elections)\n\n  state_name state_abbr historical    county_name county_fips total_votes_20\n1    Alabama         AL        red Autauga County        1001          27770\n2    Alabama         AL        red Baldwin County        1003         109679\n3    Alabama         AL        red Barbour County        1005          10518\n4    Alabama         AL        red    Bibb County        1007           9595\n5    Alabama         AL        red  Blount County        1009          27588\n6    Alabama         AL        red Bullock County        1011           4613\n  repub_pct_20 dem_pct_20 winner_20 total_votes_16 repub_pct_16 dem_pct_16\n1        71.44      27.02     repub          24661        73.44      23.96\n2        76.17      22.41     repub          94090        77.35      19.57\n3        53.45      45.79     repub          10390        52.27      46.66\n4        78.43      20.70     repub           8748        76.97      21.42\n5        89.57       9.57     repub          25384        89.85       8.47\n6        24.84      74.70       dem           4701        24.23      75.09\n  winner_16 total_votes_12 repub_pct_12 dem_pct_12 winner_12 total_population\n1     repub          23909        72.63      26.58     repub            54907\n2     repub          84988        77.39      21.57     repub           187114\n3     repub          11459        48.34      51.25       dem            27321\n4     repub           8391        73.07      26.22     repub            22754\n5     repub          23980        86.49      12.35     repub            57623\n6       dem           5318        23.51      76.31       dem            10746\n  percent_white percent_black percent_asian percent_hispanic per_capita_income\n1            76            18             1                2             24571\n2            83             9             1                4             26766\n3            46            46             0                5             16829\n4            75            22             0                2             17427\n5            88             1             0                8             20730\n6            22            71             0                6             18628\n  median_rent median_age\n1         668       37.5\n2         693       41.5\n3         382       38.3\n4         351       39.4\n5         403       39.6\n6         276       39.6\nWe’ll use this data to explore voting outcomes within the U.S.’s 2-party system. Here’s a list of candidates by year:",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#exercises-required",
    "href": "ica/ica-bi.html#exercises-required",
    "title": "\n13  Bivariate Viz\n",
    "section": "",
    "text": "2013 county-level demographics from the df_county_demographics data set from the choroplethr R package\nhistorical voting trends in the state in which the county falls (from https://www.270towin.com/content/blue-and-red-states):\n\nred = consistently Republican\nblue = consistently Democratic\npurple = something in between\n\n\n\n\n\n\n\nyear\nRepublican candidate\nDemocratic candidate\n\n\n\n2020\nDonald Trump\nJoe Biden\n\n\n2016\nDonald Trump\nHillary Clinton\n\n\n2012\nMitt Romney\nBarack Obama\n\n\n\nExercise 0: Review\nPart a\nHow many, or roughly what percent, of the 3000+ counties did the Republican candidate win in 2020?\n\nTake a guess.\nThen make a plot of the winner variable.\nThen discuss what follow-up questions you might have (and that our data might help us answer).\n\n\n# 60%?\n\nlibrary(ggplot2)\n\nggplot(elections, aes(x = winner_20)) +\n  geom_bar(color = \"white\")\n\n\n\n\n\n\n# Where are these counties concentrated?\n\nPart b\nThe repub_pct_20 variable provides more detail about the Republican support in each county. Construct a plot of repub_pct_20.\nNotice that the distribution of Republican support from county to county is slightly left skewed or negatively skewed.\nWhat follow-up questions do you have?\n\nggplot(elections, aes(x = repub_pct_20)) +\n  geom_histogram(color = \"white\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n# What does the democrat support look like?\n\nExercise 1: Quantitative vs Quantitative Intuition Check\n\n\n\n\n\n\nBe Quick\n\n\n\nDon’t spend more than 3 minutes on this!\n\n\nBelow is a scatterplot of the Republican support in 2020 vs 2016. Notice that:\n\nboth variables are quantitative, and get their own axes\nthe response variable is on the y-axis, demonstrating how repub_pct_20 might be predicted by repub_pct_16, not vice versa\n\nTry to replicate this using ggplot(). THINK:\n\nWhat info do you need to set up the canvas?\nWhat geometric layer (geom_???) might add these dots / points for each county? We haven’t learned this yet, just take some guesses.\n\n\n\nggplot(elections, aes(x = repub_pct_16, y = repub_pct_20)) +\n  geom_point()\n\n\n\n\n\n\n\nExercise 2: 2 Quantitiative Variables\nRun each chunk below to build up a a scatterplot of repub_pct_20 vs repub_pct_16 with different glyphs representing each county. Address or think about any prompts in the comments (#).\n\n# Set up the plotting frame\n# How does this differ than the frame for our histogram of repub_pct_20 alone?\n\n  #It plots repub_pct_20 against repub_pct_16\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16))\n\n\n# Add a layer of points for each county\n# Take note of the geom!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point()\n\n\n# Change the shape of the points\n# What happens if you change the shape to another number?\n  # You get some fun different points, like these crosses\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(shape = 3)\n\n\n# YOU TRY: Modify the code to make the points \"orange\"\n# NOTE: Try to anticipate if \"color\" or \"fill\" will be useful here. Then try both.\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(color = \"orange\")\n\n\n\n\n\n\n\n\n# Add a layer that represents each county by the state it's in\n# Take note of the geom and the info it needs to run!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_text(aes(label = state_abbr))\n\nExercise 3: Reflect\nSummarize the relationship between the Republican support in 2020 and 2016. Be sure to comment on:\n\nthe strength of the relationship (weak/moderate/strong)\n\nthe direction of the relationship (positive/negative)\n\noutliers (in what state do counties deviate from the national trend? Any ideas why this might be the case?)\n\nThere seems to be a strong positive relationship between republican support in 2016 and 2020, some TX counties seem to deviate from the trend\nExercise 4: Visualizing trend\nThe trend of the relationship between repub_pct_20 and repub_pct_16 is clearly positive and (mostly) linear. We can highlight this trend by adding a model “smooth” to the plot:\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth()\n\nPart a\nConstruct a new plot that contains the model smooth but does not include the individual point glyphs.\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nPart b\nBy default, geom_smooth() adds a smooth, localized model line. To examine the “best” linear model, we can specify method = \"lm\". It’s pretty similar in this example!\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\nExercise 5: Your Turn\nTo examine how the 2020 results are related to some county demographics, construct scatterplots of repub_pct_20 vs median_rent, and repub_pct_20 vs median_age. Summarize the relationship between these two variables and comment on which is the better predictor of repub_pct_20, median_rent or median_age.\n\n# Scatterplot of repub_pct_20 vs median_rent\n\nggplot(elections, aes(y = repub_pct_20, x = median_rent)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n# Scatterplot of repub_pct_20 vs median_age\n\nggplot(elections, aes(y = repub_pct_20, x = median_age)) +\n  geom_point() +\n    geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nBoth seem to be correlated, but median_rent has a stronger relationship with repub_pct_20 than median_age does\nMedian_rent has a strong negative correlation with repub_pct_20, and median_age has a weak positive correlation with repub_pct_20\nExercise 6: A Sad Scatterplot\nNext, let’s explore the relationship between a county’s 2020 Republican support repub_pct_20 and the historical political trends in its state. In this case repub_pct_20 is quantitative, but historical is categorical. Explain why a scatterplot might not be an effective visualization for exploring this relationship. (What questions does / doesn’t it help answer?)\n\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_point()\n\n\n\n\n\n\n# It doesn't help visualize the relationship between the two variables\n\nExercise 7: Quantitative vs Categorical – Violins & Boxes\nThough the above scatterplot did group the counties by historical category, it’s nearly impossible to pick out meaningful patterns in 2020 Republican support in each category. Let’s try adding 2 different geom layers to the frame:\n\n# Side-by-side violin plots\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_violin()\n\n\n# Side-by-side boxplots (defined below)\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_boxplot()\n\nBox plots are constructed from five numbers - the minimum, 25th percentile, median, 75th percentile, and maximum value of a quantitative variable:\n\nREFLECT:\nSummarize what you’ve learned about the 2020 Republican county-level support within and between red/purple/blue states.\nRepublicans have much stronger county-level support within red states, slightly weaker support in purple states, and even weaker support in blue states.\nExercise 8: Quantitative vs Categorical – Intuition Check\n\n\n\n\n\n\nBe Quick\n\n\n\nDon’t spend more than 3 minutes on this!\n\n\nWe can also visualize the relationship between repub_pct_20 and historical using our familiar density plots. In the plot below, notice that we simply created a separate density plot for each historical category. (The plot itself is “bad” but we’ll fix it below.) Try to adjust the code chunk below, which starts with a density plot of repub_pct_20 alone, to re-create this image.\n\n\nggplot(elections, aes(x = repub_pct_20)) +\n  geom_density(fill = \"blue\")\n\n\n\n\n\n\n\nExercise 9: Quantitative vs Categorical – Density Plots\nWork through the chunks below and address the comments therein.\n\n# Name two \"bad\" things about this plot\n\n# We aren't able to see the full graphs for each historical variable and the colors don't align with the variables\n\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density()\n\n\n# What does scale_fill_manual do?\n# It lets you choose the fill color for each variable independantly\n\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n# What does alpha = 0.5 do?\n# Lowers the opacity of each historical variable\n\n# Play around with different values of alpha, between 0 and 1\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.25) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n# What does facet_wrap do?!\n\n#facet_wrap splits up the historical variable, putting each on its own plot\n\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  facet_wrap(~ historical)\n\n\n# Let's try a similar grouping strategy with a histogram instead of density plot.\n# Why is this terrible?\n\n# Stacking the data on top of each other makes it harder to tell how much there is for each category\n\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_histogram(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\nExercise 10\nWe’ve now learned 3 (of many) ways to visualize the relationship between a quantitative and categorical variable: side-by-side violins, boxplots, and density plots.\n\nWhich do you like best?\n\nBoth are good but I think I prefer density plots\n\nWhat is one pro of density plots relative to boxplots?\n\nIt’s a lot easier to get a sense of relative distribution of different variables\n\nWhat is one con of density plots relative to boxplots?\n\nBoxplots provide a more clear visualization of outliers\nExercise 11: Categorical vs Categorical – Intuition Check\nFinally, let’s simply explore who won each county in 2020 (winner_20) and how this breaks down by historical voting trends in the state. That is, let’s explore the relationship between 2 categorical variables! Following the same themes as above, we can utilize grouping features such as fill/color or facets to distinguish between different categories of winner_20 and historical.\n\n\n\n\n\n\nBe Quick\n\n\n\nSpend at most 5 minutes on the following intuition check. Adjust the code below to recreate the following two plots.\n\n\n\n\n# Plot 1: adjust this to recreate the top plot\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar() + \n  scale_fill_manual(values = c(\"salmon\", \"turquoise\"))\n\n\n\n\n\n\n\n\n# Plot 2: adjust this to recreate the bottom plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n\nExercise 12: Categorical vs Categorical\nConstruct the following 4 bar plot visualizations.\n\n# A stacked bar plot\n# How are the \"historical\" and \"winner_20\" variables mapped to the plot, i.e. what roles do they play?\n\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar()\n\n# Each subset of historical is its own bar that winner_20 is stacked on top of\n\n\n# A faceted bar plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n# A side-by-side bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"dodge\")\n\n\n# A proportional bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"fill\")\n\nPart a\nName one pro and one con of using the “proportional bar plot” instead of one of the other three options.\nOne pro is that it makes it very clear that each section adds up to 100% of the data so it’s easier to see their relative frequencies\nOne con is that it can be harder to compare the frequencies of the data stacked on top since it doesn’t begin at the bottom of the frame\nPart b\nWhat’s your favorite bar plot from part and why?\nProbably the overlapping density plot since it’s easy to see both relative frequencies and distributions with it\nExercise 13: Practice (now or later)\n\n\n\n\n\n\nDecide\n\n\n\nDecide what’s best for you:\n\nTry this extra practice now.\nReflect on the above exercises and come back to this extra practice later (but before the next class).\n\n\n\nImport some daily weather data from a few locations in Australia:\n\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n\nhead(weather)\n\n        date   location mintemp maxtemp rainfall evaporation sunshine\n1 2020-01-01 Wollongong    17.1    23.1        0          NA       NA\n2 2020-01-02 Wollongong    17.7    24.2        0          NA       NA\n3 2020-01-03 Wollongong    19.7    26.8        0          NA       NA\n4 2020-01-04 Wollongong    20.4    35.5        0          NA       NA\n5 2020-01-05 Wollongong    19.8    21.4        0          NA       NA\n6 2020-01-06 Wollongong    18.3    22.9        0          NA       NA\n  windgustdir windgustspeed winddir9am winddir3pm windspeed9am windspeed3pm\n1         SSW            39        SSW        SSE           20           15\n2         SSW            37          S        ENE           13           15\n3          NE            41        NNW        NNE            7           17\n4         SSW            78         NE        NNE           15           17\n5         SSW            57        SSW          S           31           35\n6          NE            35        ESE         NE           17           20\n  humidity9am humidity3pm pressure9am pressure3pm cloud9am cloud3pm temp9am\n1          69          64      1014.9      1014.0        8        1    19.1\n2          72          54      1020.1      1017.7        7        1    19.8\n3          72          71      1017.5      1013.0        6       NA    23.4\n4          77          69      1008.8      1003.9       NA       NA    24.5\n5          70          75      1018.9      1019.9       NA        7    20.7\n6          71          71      1021.2      1018.2       NA       NA    20.9\n  temp3pm raintoday risk_mm raintomorrow\n1    22.9        No     0.0           No\n2    23.6        No     0.0           No\n3    25.7        No     0.0           No\n4    26.7        No     0.0           No\n5    20.0        No     0.0           No\n6    22.6        No     0.8           No\n\n\nConstruct plots that address the research questions in each chunk. You might make multiple plots–there are many ways to do things!. However, don’t just throw spaghetti at the wall.\nReflect before doing anything. What types of variables are these? How might you plot just 1 of the variables, and then tweak the plot to incorporate the other?\n\n# How do 3pm temperatures (temp3pm) differ by location?\n\nggplot(weather, aes(x = temp3pm, fill = location)) +\n  geom_density(alpha = 0.5)\n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n# How might we predict the 3pm temperature (temp3pm) by the 9am temperature (temp9am)?\n\nggplot(weather, aes(x = temp9am, y = temp3pm)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 27 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n# How do the number of rainy days (raintoday) differ by location?\n\nggplot(weather, aes(x = raintoday)) +\n  geom_bar(color = \"white\", fill = \"turquoise\") +\n  facet_wrap(~ location)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html#solutions",
    "href": "ica/ica-bi.html#solutions",
    "title": "\n13  Bivariate Viz\n",
    "section": "\n13.2 Solutions",
    "text": "13.2 Solutions\n\nClick for Solutions\n\n# Import data\nsurvey &lt;- read.csv(\"https://ajohns24.github.io/data/112/about_us_2024.csv\")\n\n# How many students have now filled out the survey?\nnrow(survey)\n\n[1] 28\n\n# What type of variables do we have?\nstr(survey)\n\n'data.frame':   28 obs. of  4 variables:\n $ cafe_mac         : chr  \"Cheesecake\" \"Cheese pizza\" \"udon noodles\" \"egg rolls\" ...\n $ minutes_to_campus: int  15 10 4 7 5 35 5 15 7 20 ...\n $ fave_temp        : num  18 24 18 10 18 7 75 24 13 16 ...\n $ hangout          : chr  \"the mountains\" \"a beach\" \"the mountains\" \"a beach\" ...\n\n\nEXAMPLE 1: Hangout preferences\n\n# Attach a package needed to use the ggplot function\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Make a ggplot\nggplot(survey, aes(x = hangout)) + \n  geom_bar()\n\n\n\n\n\n\n\nEXAMPLE 2: Temperature preferences\n\nggplot(survey, aes(x = fave_temp)) + \n  geom_histogram(color = \"white\", binwidth = 5)\n\n\n\n\n\n\nggplot(survey, aes(x = fave_temp)) + \n  geom_density()\n\n\n\n\n\n\n\n\n13.2.1 Exercise 0:\n\nggplot(elections, aes(x = winner_20)) + \n  geom_bar()\n\n\n\n\n\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_histogram(color = \"white\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_density()\n\n\n\n\n\n\n\nExercise 1: quantitative vs quantitative intuition check\nSee next exercise.\nExercise 2: 2 quantitiative variables\n\n# Set up the plotting frame\n# How does this differ than the frame for our histogram of repub_pct_20 alone?\n# ANSWER: we added a y-axis variable\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16))\n\n\n\n\n\n\n# Add a layer of points for each county\n# Take note of the geom: geom_point\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point()\n\n\n\n\n\n\n# Change the shape of the points\n# What happens if you change the shape to another number?\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(shape = 3)\n\n\n\n\n\n\n# YOU TRY: Modify the code to make the points \"orange\"\n# NOTE: Try to anticipate if \"color\" or \"fill\" will be useful here. Then try both.\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(color = \"orange\")\n\n\n\n\n\n\n# Add a layer that represents each county by the state it's in\n# Take note of the geom and the info it needs to run!\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_text(aes(label = state_abbr))\n\n\n\n\n\n\n\nExercise 3: Reflect\nThere’s a strong, positive association – the higher the Republican support in 2016, the higher it was in 2020. There are some counties in Texas and Utah where the R support in 2020 was disproportionately higher than in 2016.\nExercise 4: Visualizing trend\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nPart a\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\nPart b\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nExercise 5: Your turn\nThere’s a moderate, positive association between R support and median age – the older the average age in a county, the higher the R support tends to be. However, there’s a stronger, negative association between R support and median rent – the higher the rent (a proxy for cost of living), the lower the R support tends to be.\n\n# Scatterplot of repub_pct_20 vs median_rent\nggplot(elections, aes(y = repub_pct_20, x = median_rent)) +\n  geom_point() \n\n\n\n\n\n\n# Scatterplot of repub_pct_20 vs median_age\nggplot(elections, aes(y = repub_pct_20, x = median_age)) +\n  geom_point() \n\n\n\n\n\n\n\nExercise 6: A sad scatterplot\nSee next exercise.\nExercise 7: quantitative vs categorical – violins & boxes\n\n# Side-by-side violin plots\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_violin()\n\n\n\n\n\n\n# Side-by-side boxplots (defined below)\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nREFLECT:\nThere’s quite a bit of range in county-level R support within blue, purple, and red states. However, R support tends to be higher in red states and lower in blue states.\nExercise 8: quantitative vs categorical – intuition check\nSee next exercise.\nExercise 9: quantitative vs categorical – density plots\n\n# The colors used don't match up with the blue, purple, red labels\n# The density plots are on top of each other\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density()\n\n\n\n\n\n\n# scale_fill_manual \"hard codes\" or defines what colors to use for the fill categories\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n# alpha = 0.5 adds transparency\n# the closer alpha is to 0, the more transparent.\n# the closer alpha is to 1, the more opaque.\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n# facet_wrap separates the density plots into \"facets\" for each historical group\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n# Let's try a similar grouping strategy with a histogram instead of density plot.\n# Why is this terrible?\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_histogram(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nExercise 10\n\nOne pro of density plots relative to boxplots: doesn’t oversimplify the data / boil the data down to just 5 numbers.\nName one con of density plots relative to boxplots: boxplots can be easier to interpret\nExercise 11: categorical vs categorical intuition check\nsee exercise below\nExercise 12: categorical vs categorical\n\n# A stacked bar plot\n# historical = x axis / bar categories\n# winner_20 = fills the bars\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar()\n\n\n\n\n\n\n# A faceted bar plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n# A side-by-side bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n# A proportional bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nPart a\npro = easier to compare the relative outcomes in blue vs purple vs red states con = lose track of how many counties fall into blue vs purple vs red states\nExercise 13: Practice (now or later)\n\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n\n# How do 3pm temperatures (temp3pm) differ by location?\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5)\n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\nggplot(weather, aes(y = temp3pm, x = location)) + \n  geom_boxplot()\n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n# How might we predict the 3pm temperature (temp3pm) by the 9am temperature (temp9am)?\nggplot(weather, aes(y = temp3pm, x = temp9am)) + \n  geom_point()\n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n# How do the number of rainy days (raintoday) differ by location?\nggplot(weather, aes(x = location, fill = raintoday)) + \n  geom_bar()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html",
    "href": "ica/ica-multi.html",
    "title": "\n14  Multivariate Viz\n",
    "section": "",
    "text": "The story\nThough far from a perfect assessment of academic preparedness, SAT scores have historically been used as one measurement of a state’s education system. The education dataset contains various education variables for each state:\n# Import and check out data\neducation &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nhead(education)\n\n       State expend ratio salary frac verbal math  sat  fracCat\n1    Alabama  4.405  17.2 31.144    8    491  538 1029   (0,15]\n2     Alaska  8.963  17.6 47.951   47    445  489  934 (45,100]\n3    Arizona  4.778  19.3 32.175   27    448  496  944  (15,45]\n4   Arkansas  4.459  17.1 28.934    6    482  523 1005   (0,15]\n5 California  4.992  24.0 41.078   45    417  485  902  (15,45]\n6   Colorado  5.443  18.4 34.571   29    462  518  980  (15,45]\nA codebook is provided by Danny Kaplan who also made these data accessible:",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html#solutions",
    "href": "ica/ica-multi.html#solutions",
    "title": "\n14  Multivariate Viz\n",
    "section": "\n14.1 Solutions",
    "text": "14.1 Solutions\n\nClick for Solutions\nExercise 1: SAT scores\nPart a\n\n# A histogram would work too!\nggplot(education, aes(x = sat)) + \n  geom_density()\n\n\n\n\n\n\n\nPart b\naverage SAT scores range from roughly 800 to 1100. They appear bi-modal.\nExercise 2: SAT Scores vs Per Pupil Spending & SAT Scores vs Salaries\nPart a\n\n# Construct a plot of sat vs expend\n# Include a \"best fit linear regression model\"\nggplot(education, aes(y = sat, x = expend)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n# Construct a plot of sat vs salary\n# Include a \"best fit linear regression model\"\nggplot(education, aes(y = sat, x = salary)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nPart b\nThe higher the student expenditures and teacher salaries, the worse the SAT performance.\nExercise 3: SAT Scores vs Per Pupil Spending and Teacher Salaries\n\nggplot(education, aes(y = sat, x = salary, color = expend)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation:\ncolour.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\nExercise 4: Another Way to Incorporate Scale\n\nggplot(education, aes(y = sat, x = salary, color = cut(expend, 2))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nggplot(education, aes(y = sat, x = salary, color = cut(expend, 3))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nStates with lower salaries and expenditures tend to have higher SAT scores.\nExercise 5: Finally an Explanation\nPart a\n\nggplot(education, aes(x = fracCat)) + \n  geom_bar()\n\n\n\n\n\n\n\nPart b\nThe more students in a state that take the SAT, the lower the average scores tend to be. This is probably related to self-selection.\n\nggplot(education, aes(x = sat, fill = fracCat)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nPart c\nWhen we control for the fraction of students that take the SAT, SAT scores increase with expenditure.\n\nggplot(education, aes(y = sat, x = expend, color = fracCat)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nPart d\nStudent participation tends to be lower among states with lower expenditures (which are likely also the states with higher ed institutions that haven’t historically required the SAT). Those same states tend to have higher SAT scores because of the self-selection of who participates.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Multivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html",
    "href": "ica/ica-spatial.html",
    "title": "\n15  Spatial Viz\n",
    "section": "",
    "text": "Exercise 1: A leaflet with markers / points\nEarlier this semester, I asked for the latitude and longitude of one of your favorite places. I rounded these to the nearest whole number, so that they’re near to but not exactly at those places. Let’s load the data and map it!\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\n\n  latitude longitude\n1       59        18\n2       45       -93\n3       33      -117\n4       40       116\n5       40       106\n6       37      -122",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html#solutions",
    "href": "ica/ica-spatial.html#solutions",
    "title": "\n15  Spatial Viz\n",
    "section": "\n15.1 Solutions",
    "text": "15.1 Solutions\n\nClick for Solutions\nExercise 3: A simple scatterplot\nIt would be nice to also have some actual reference maps of countries in the background.\n\nggplot(starbucks, aes(y = Latitude, x = Longitude)) + \n  geom_point(size = 0.5)\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nExercise 6: A state and county-level map\nPart b\nAdjust the code below to make the plot! Remove the # to run it.\n\nggplot(midwest_boundaries) +\n  geom_sf() +\n  geom_point(\n    data = starbucks_midwest,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.7,\n    size = 0.2,\n    color = 'darkgreen'\n  ) +\n  theme_map()\n\n\n\n\n\n\n\nExercise 7: Contour maps\nEspecially when there are lots of point locations, and those locations start overlapping on a map, it can be tough to visualize areas of higher density. Consider the Starbucks locations in Canada, Mexico, and the US that we mapped earlier:\n\n# Point map (we made this earlier)\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\nNow check out the contour map.\n\n# What changed in the plot?\n# What changed in our code?!\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_density_2d(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\nExercises Part 3: Choropleth maps\nSpatial data isn’t always in the form of point locations! For example, recall the state and county-level data on presidential elections.\n\nelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\nIn these datasets, we’re interested in the overall election outcome by region (state or county), not the specific geographic location of some observation. Let’s wrangle our data first.\nWe’ll focus on just a few variables of interest, and create a new variable (repub_20_categories) that discretizes the repub_pct_20 variable into increments of 5 percentage points (for states) or 10 percentage points (for counties):\n\n# Don't worry about the code!\n\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\n# Add 0's at the beginning of any fips_code that's fewer than 5 numbers long\n# Don't worry about the syntax\nelections_by_counties &lt;- elections_by_counties |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips))\n\nExercise 8: State-level choropleth maps\nPart d\ngeom_map()\nExercise 10: Play around!\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_rent)) +\n  geom_map(map = county_map) +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal() + \n  scale_fill_gradientn(name = \"median rent\", colors = c(\"white\", \"lightgreen\", \"darkgreen\"))\n\n\n\n\n\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_age)) +\n  geom_map(map = county_map) +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal() + \n  scale_fill_gradientn(name = \"median age\", colors = terrain.colors(10))",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html",
    "href": "ica/ica-effective.html",
    "title": "\n16  Effective Viz\n",
    "section": "",
    "text": "16.1 Exercises",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html#exercises",
    "href": "ica/ica-effective.html#exercises",
    "title": "\n16  Effective Viz\n",
    "section": "",
    "text": "Exercise 1: Professionalism\nLet’s examine weather in 3 Australian locations.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nThe following plot is fine for things like homework or just playing around. But we’ll make it more “professional” looking below.\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point()\n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nPart a\nReplace A, B, C, and D in the code below to:\n\nAdd a short, but descriptive title. Under 10 words.\nChange the x- and y-axis labels, currently just the names of the variables in the dataset. These should be short and include units.\nChange the legend title to “Location” (just for practice, not because it’s better than “location”).\n\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() + \n  labs(x = \"9 am Temperature\", y = \"3 pm Temperature\", title = \"9 am vs. 3 pm Temperature by Location in Australia\", color = \"Location\")  \n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nPart b\nWhen we’re including our plot in an article, paper, book, or other similar outlet, we should (and are expected to) provide a more descriptive figure caption. Typically, this is instead of a title and is more descriptive of what exactly is being plotted.\n\nAdd a figure caption in the top of the chunk.\nInclude your x-axis, y-axis, and legend labels from Part a.\nRender your Rmd and check out how the figure caption appears.\n\n\nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() + \n  labs(x = \"9 am Temperature\", y = \"3 pm Temperature\", color = \"Location\")  \n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\nPlot of temperature at 9 am and 3 pm across different Australian locations\n\n\n\n\nExercise 2: Accessibility\nLet’s now make a graphic more accessible.\n\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\")  \n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\nDensity plots of 3pm temperatures in 3 Australian locations.\n\n\n\nPart a\nLet’s add some alt text that can be picked up by screen readers. This is a great resource on writing alt text for data viz. In short, whereas figure captions are quick descriptions which assume that the viz is accessible, alt text is a longer description which assumes the viz is not accessible. Alt text should concisely articulate:\n\nWhat your visualization is (e.g. a density plot of 3pm temperatures in Hobart, Uluru, and Wollongong, Australia).\nA 1-sentence description of the most important takeaway.\nA link to your data source if it’s not already in the caption.\n\nAdd appropriate alt text at the top of the chunk, in fig-alt. Then knit your Rmd, and hover over the image in your knitted html file to check out the alt text.\n\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\")  \n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\nDensity plots of 3pm temperatures in 3 Australian locations.\n\n\n\n\nPart b\nColor is another important accessibility consideration. Let’s check out the color accessibility of our density plot.\n\nRun the ggplot() code from Part a in your console. The viz will pop up in the Plots tab.\nIn the Plots tab, click “Export” then “Save as image”. Save the image somewhere.\nNavigate to https://www.color-blindness.com/coblis-color-blindness-simulator/\n\nAbove the image of crayons (I think it’s crayons?), click “Choose file” and choose the plot file you just saved.\nClick the various simulator buttons (eg: Red-Weak/Protanomaly) to check out how the colors in this plot might appear to others.\nSummarize what you learn. What impact might our color choices have on one’s ability to interpret the viz?\n\nSome types of color blindness may make different segments of the graph appear to be the same color, making it more difficult to interpret the data.\nPart c\nWe can change our color schemes! There are many color-blind friendly palettes in R. In the future, we’ll set a default, more color-blind friendly color theme at the top of our Rmds. We can also do this individually for any plot that uses color. Run the chunks below to explore various options.\n\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\") + \n  scale_fill_viridis_d()    \n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n# In the color scale line:\n# Change \"fill\" to \"color\" since we use color in the aes()\n# Change \"d\" (discrete) to \"c\" (continuous) since maxtemp is on a continuous scale\nggplot(weather, aes(y = temp3pm, x = temp9am, color = maxtemp)) + \n  geom_point(alpha = 0.5) + \n  labs(x = \"3pm temperature (Celsius)\") + \n  scale_color_viridis_c()\n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nExercise 3: Ethics\nLet’s scratch the surface of ethics in data viz. Central to this discussion is the consideration of impact.\nPart a\nAt a minimum, our data viz should not mislead. Reconsider the climate change example from above. Why is this plot unethical and what impact might it have on policy, public opinion, etc?\nThis plot is unethical in the way it hides the signifigance of the temperature increase.\n\nPart b\nAgain, data viz ethical considerations go beyond whether or not a plot is misleading. As described in the warm-up, we need to consider: visibility, privacy, power, emotion & embodiment, pluralism, & context. Depending upon the audience and goals of a data viz, addressing these points might require more nuance. Mainly, the viz tools we’ve learned are a great base or foundation, but aren’t the only approaches to data viz. \nPick one or more of the following examples of data viz to discuss with your group. How do the approaches taken:\n\nemphasize one or more of: visibility, privacy, power, emotion, embodiment, pluralism, and/or context?\nimprove upon what we might be able to convey with a simpler bar chart, scatterplot, etc?\n\n\nExample: W.E.B. Du Bois (1868–1963)\nDu Bois (“Doo Boys”) was a “sociologist, socialist, historian, civil rights activist, Pan-Africanist, author, writer, and editor”1. He was also a pioneer in elevating emotion and embodiment in data visualization. For the Paris World Fair of 1900, Du Bois and his team of students from Atlanta University presented 60 data visualizations of the Black experience in America, less than 50 years after the abolishment of slavery. Du Bois noted: “I wanted to set down its aim and method in some outstanding way which would bring my work to notice by the thinking world.” That is, he wanted to increase the impact of his work by partnering technical visualizations with design that better connects to lived experiences. NOTE: This work uses language common to that time period and addresses the topic of slavery. Check out:\n\nA complete set of the data visualizations provided by Anthony Starks (@ajstarks).\nAn article by Allen Hillery (@AlDatavizguy).\n\n\nExample: One person’s experience with long COVID\nNYT article\n\nExample: Decolonizing data viz\nblog post\n\nExample: Visualizing climate change through art\nFutures North with Prof John Kim & Mac students (by Prof Kim, Mac research students)\n\nExample: Personal data collection\nDear Data\n\nPart c\nFor a deeper treatment of similar topics, and more examples, read Data Feminism.\n\nExercise 4: Critique\nPractice critiquing some more complicated data viz listed at Modern Data Science with R, Exercise 2.5.\nThink about the following questions:\n\nWhat story does the data graphic tell? What is the main message that you take away from it?\nCan the data graphic be described in terms of the Grammar of Graphics (frame, glyphs, aesthetics, facet, scale, guide)? If so, please describe.\nCritique and/or praise the visualization choices made by the designer. Do they work? Are they misleading? Thought-provoking? Are there things that you would have done differently?\n\n\nExercise 5: Design Details\nThis final exercise is just “food for thought”. It’s more of a discussion than an exercise, and gets into some of the finer design details and data viz theory. Go as deep or not deep as you’d like here.\nIn refining the details of our data viz, Visualize This and Storytelling with Data provide some of their guiding principles. But again, every context is different.\n\nPut yourself in a reader’s shoes. What parts of the data need explanation?\nShine a light on your data. Try to remove any “chart junk” that distracts from the data.\nVary color and style to emphasize the viz elements that are most important to the story you’re telling.\nIt is easier to judge length than it is to judge area or angles.\nBe thoughtful about how your categories are ordered for categorical data.\n\nGetting into even more of the nitty gritty, we need to be mindful of what geometric elements and aesthetics we use. The following elements/aesthetics are listed in roughly descending order of human ability to perceive and compare nearby objects:2\n\nPosition\nLength\nAngle\nDirection\nShape (but only a very few different shapes)\nArea\nVolume\nShade\nColor. (Color is the most difficult, because it is a 3-dimensional quantity.)\n\nFinally, here are some facts to keep in mind about visual perception from Now You See It.\nPart a: Selectivity\nVisual perception is selective, and our attention is often drawn to contrasts from the norm.\nImplication: We should design visualizations so that the features we want to highlight stand out in contrast from those that are not worth the audience’s attention.\nExample: What stands out in this example image? This is originally from C. Ware, Information Visualization: Perception for Design, 2004? Source: S. Few, Now You See It, 2009, p. 33.\n\nPart b: Familiarity\nOur eyes are drawn to familiar patterns. We observe what we know and expect.\nImplication: Visualizations work best when they display information as patterns that familiar and easy to spot.\nExample: Do you notice anything embedded in this rose image from coolbubble.com? Source: S. Few, Now You See It, 2009, p. 34.\n\nPart c: Revisit\nRevisit Part b. Do you notice anything in the shadows? Go to https://mac-stat.github.io/images/112/rose2.png for an image.\n\nWrapping up\nIf you finish early:\n\nWork on homework if not done already\nComplete any activities you haven’t finished yet, eg, spatial viz, the optional but fun exercises in the Multivariate viz and Bivariate viz activities.\nIf you’ve done all that, explore some datasets in TidyTuesday.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html#solutions",
    "href": "ica/ica-effective.html#solutions",
    "title": "\n16  Effective Viz\n",
    "section": "\n16.2 Solutions",
    "text": "16.2 Solutions\nThe exercises today are discussion based. There are no “solutions”. Happy to chat in office hours about any ideas here!",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-effective.html#footnotes",
    "href": "ica/ica-effective.html#footnotes",
    "title": "\n16  Effective Viz\n",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/W._E._B._Du_Bois↩︎\nB. S. Baumer, D. T. Kaplan, and N. J. Horton, Modern Data Science with R, 2017, p. 15.↩︎",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Effective Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html",
    "href": "ica/ica-wrangling.html",
    "title": "\n17  Wrangling\n",
    "section": "",
    "text": "Exercise 1: select Practice\nUse select() to create a simplified dataset that we’ll use throughout the exercises below.\n# Load tidyverse & data\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n# Define elections_small\nelections_small &lt;- elections |&gt;\n  select(state_name, county_name, total_votes_20, repub_pct_20, dem_pct_20, total_votes_16, dem_pct_16)\n\n# Check out the first 6 rows to confirm your code did what you think it did!\n\nhead(elections_small)\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16\n1          24661      23.96\n2          94090      19.57\n3          10390      46.66\n4           8748      21.42\n5          25384       8.47\n6           4701      75.09",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-wrangling.html#solutions",
    "href": "ica/ica-wrangling.html#solutions",
    "title": "\n17  Wrangling\n",
    "section": "\n17.1 Solutions",
    "text": "17.1 Solutions\n\nClick for Solutions\n\n17.1.1 Example 1\n\nselect\nfilter\nmutate\narrange\nsummarize\nExercise 1: select Practice\n\n# Define elections_small\nelections_small &lt;- elections |&gt;\n  select(state_name, county_name, total_votes_20, repub_pct_20, dem_pct_20, total_votes_16, dem_pct_16)\n\n# Check out the first 6 rows to confirm your code did what you think it did!\nhead(elections_small)\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16\n1          24661      23.96\n2          94090      19.57\n3          10390      46.66\n4           8748      21.42\n5          25384       8.47\n6           4701      75.09\n\n\nExercise 2: filter Demo\n\n# Keep only data on counties in Hawaii\nelections_small |&gt;\n filter(state_name == \"Hawaii\")\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1     Hawaii   Hawaii County          87814        30.63      66.88\n2     Hawaii Honolulu County         382114        35.66      62.51\n3     Hawaii    Kauai County          33497        34.58      63.36\n4     Hawaii     Maui County          71044        31.14      66.59\n  total_votes_16 dem_pct_16\n1          64865      63.61\n2         285683      61.48\n3          26335      62.49\n4          51942      64.45\n\n\n\n# Keep counties in Hawaii AND Delaware\nelections_small |&gt; \n  filter(state_name %in% c(\"Hawaii\", \"Delaware\"))\n\n  state_name       county_name total_votes_20 repub_pct_20 dem_pct_20\n1   Delaware       Kent County          87025        47.12      51.19\n2   Delaware New Castle County         287633        30.72      67.81\n3   Delaware     Sussex County         129352        55.07      43.82\n4     Hawaii     Hawaii County          87814        30.63      66.88\n5     Hawaii   Honolulu County         382114        35.66      62.51\n6     Hawaii      Kauai County          33497        34.58      63.36\n7     Hawaii       Maui County          71044        31.14      66.59\n  total_votes_16 dem_pct_16\n1          74253      44.91\n2         261468      62.30\n3         105814      37.17\n4          64865      63.61\n5         285683      61.48\n6          26335      62.49\n7          51942      64.45\n\n\n\n# Keep only data on counties where the Republican got MORE THAN 93.97% of the vote in 2020\nelections_small |&gt; \n  filter(repub_pct_20 &gt; 93.97)\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  Borden County            416        95.43       3.85\n2      Texas    King County            159        94.97       5.03\n3      Texas Roberts County            550        96.18       3.09\n  total_votes_16 dem_pct_16\n1            365       8.49\n2            159       3.14\n3            550       3.64\n\n\n\n# Keep only data on counties where the Republican got AT LEAST 93.97% of the vote in 2020\n# This should have 1 more row than your answer above\nelections_small |&gt; \n  filter(repub_pct_20 &gt;= 93.97)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Montana Garfield County            813        93.97       5.04\n2      Texas   Borden County            416        95.43       3.85\n3      Texas     King County            159        94.97       5.03\n4      Texas  Roberts County            550        96.18       3.09\n  total_votes_16 dem_pct_16\n1            715       4.76\n2            365       8.49\n3            159       3.14\n4            550       3.64\n\n\n\n# Keep only data on counties in Texas where the Democrat got more than 65% of the vote in 2020\n# Do this 2 ways.\n# Method 1: 2 filters with 1 condition each\nelections_small |&gt;\n filter(state_name == \"Texas\") |&gt;\n filter(dem_pct_20 &gt; 65)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  El Paso County         267215        31.56      66.66\n2      Texas Presidio County           2217        32.52      65.99\n3      Texas   Travis County         610349        26.43      71.41\n4      Texas   Zavala County           4379        34.03      65.40\n  total_votes_16 dem_pct_16\n1         210458      69.14\n2           2203      66.18\n3         462511      66.26\n4           3390      77.67\n\n# Method 2: 1 filter with 2 conditions\nelections_small |&gt;\n filter(state_name == \"Texas\", dem_pct_20 &gt; 65)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  El Paso County         267215        31.56      66.66\n2      Texas Presidio County           2217        32.52      65.99\n3      Texas   Travis County         610349        26.43      71.41\n4      Texas   Zavala County           4379        34.03      65.40\n  total_votes_16 dem_pct_16\n1         210458      69.14\n2           2203      66.18\n3         462511      66.26\n4           3390      77.67\n\n\nExercise 3: arrange Demo\n\n# Arrange the counties in elections_small from lowest to highest percentage of 2020 Republican support\n# Print out just the first 6 rows\nelections_small |&gt;\n  arrange(repub_pct_20) |&gt;\n  head()\n\n            state_name            county_name total_votes_20 repub_pct_20\n1 District of Columbia   District of Columbia         344356         5.40\n2             Maryland Prince George's County         424855         8.73\n3             Maryland         Baltimore city         237461        10.69\n4             Virginia        Petersburg city          14118        11.22\n5             New York        New York County         694904        12.26\n6           California   San Francisco County         443458        12.72\n  dem_pct_20 total_votes_16 dem_pct_16\n1      92.15         280272      92.85\n2      89.26         351091      89.33\n3      87.28         208980      85.44\n4      87.75          13717      87.52\n5      86.78         591368      87.17\n6      85.27         365295      85.53\n\n\n\n# Arrange the counties in elections_small from highest to lowest percentage of 2020 Republican support\n# Print out just the first 6 rows\nelections_small |&gt;\n  arrange(desc(repub_pct_20)) |&gt;\n  head()\n\n  state_name      county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas   Roberts County            550        96.18       3.09\n2      Texas    Borden County            416        95.43       3.85\n3      Texas      King County            159        94.97       5.03\n4    Montana  Garfield County            813        93.97       5.04\n5      Texas Glasscock County            653        93.57       5.97\n6   Nebraska     Grant County            402        93.28       4.98\n  total_votes_16 dem_pct_16\n1            550       3.64\n2            365       8.49\n3            159       3.14\n4            715       4.76\n5            602       5.65\n6            394       5.08\n\n\nExercise 4: mutate Demo\n\n# Define diff_20, the difference btwn the Repub and Dem percent in 2020\nelections_small |&gt; \n  mutate(diff_20 = repub_pct_20 - dem_pct_20) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 diff_20\n1          24661      23.96   44.42\n2          94090      19.57   53.76\n3          10390      46.66    7.66\n4           8748      21.42   57.73\n5          25384       8.47   80.00\n6           4701      75.09  -49.86\n\n\n\n# Define repub_votes_20, the number (not percent) of Repub votes in 2020\nelections_small |&gt; \n  mutate(repub_votes_20 = round(total_votes_20 * repub_pct_20/100)) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_votes_20\n1          24661      23.96          19839\n2          94090      19.57          83542\n3          10390      46.66           5622\n4           8748      21.42           7525\n5          25384       8.47          24711\n6           4701      75.09           1146\n\n\n\n# Define repub_win_20, whether the Repub won in 2020 (TRUE or FALSE!)\nelections_small |&gt; \n  mutate(repub_win_20 = repub_pct_20 &gt; dem_pct_20) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_win_20\n1          24661      23.96         TRUE\n2          94090      19.57         TRUE\n3          10390      46.66         TRUE\n4           8748      21.42         TRUE\n5          25384       8.47         TRUE\n6           4701      75.09        FALSE\n\n\nExercise 5: Pipe Series\nPart c\nIt’s more “computationally efficient” to get rid of some rows before arranging.\nPart e\nWe can’t select a variable before we define it!\nExercise 6: DIY Pipe Series\nPart a\nHere’s my translation:\n\njust the counties in Minnesota —&gt; filter\njust the counties in Minnesota and their Democratic 2020 vote percentage —&gt; select\nfrom highest to lowest —&gt; arrange\n\n\n# Remember to try this 1 line at a time\nelections_small |&gt; \n  filter(state_name == \"Minnesota\") |&gt; \n  select(county_name, dem_pct_20) |&gt; \n  arrange(desc(dem_pct_20))\n\n                county_name dem_pct_20\n1             Ramsey County      71.50\n2           Hennepin County      70.46\n3               Cook County      65.58\n4          St. Louis County      56.64\n5             Dakota County      55.73\n6            Olmsted County      54.16\n7         Washington County      53.46\n8         Blue Earth County      50.84\n9               Clay County      50.74\n10              Lake County      50.64\n11          Nicollet County      50.31\n12           Carlton County      49.58\n13            Winona County      49.07\n14              Rice County      48.76\n15          Mahnomen County      48.26\n16             Anoka County      47.79\n17          Beltrami County      47.24\n18            Carver County      46.37\n19             Mower County      46.00\n20             Scott County      45.52\n21           Houston County      42.42\n22           Goodhue County      41.23\n23          Freeborn County      40.96\n24            Norman County      40.80\n25            Itasca County      40.61\n26       Koochiching County      38.41\n27          Watonwan County      38.20\n28           Kittson County      38.12\n29           Stevens County      37.80\n30           Stearns County      37.58\n31          Fillmore County      37.48\n32            Steele County      37.47\n33         Kandiyohi County      36.12\n34            Aitkin County      35.98\n35              Lyon County      35.94\n36     Lac qui Parle County      35.79\n37           Wabasha County      35.78\n38             Grant County      35.58\n39          Traverse County      35.46\n40         Big Stone County      35.41\n41        Pennington County      35.29\n42              Pope County      35.27\n43              Polk County      34.88\n44              Cass County      34.68\n45            Wright County      34.49\n46           Hubbard County      34.42\n47             Swift County      34.35\n48         Crow Wing County      34.17\n49           Chisago County      34.15\n50            Becker County      33.96\n51              Pine County      33.87\n52          Le Sueur County      33.73\n53          Chippewa County      33.67\n54            Nobles County      33.65\n55            Waseca County      33.65\n56             Dodge County      33.47\n57        Otter Tail County      32.85\n58            Benton County      32.70\n59           Douglas County      32.56\n60             Brown County      32.48\n61         Sherburne County      32.48\n62         Faribault County      31.98\n63          Red Lake County      31.47\n64          Renville County      30.71\n65            McLeod County      30.64\n66   Yellow Medicine County      30.54\n67           Lincoln County      30.08\n68        Cottonwood County      30.03\n69           Kanabec County      30.02\n70            Martin County      30.02\n71           Jackson County      29.99\n72        Mille Lacs County      29.98\n73            Wilkin County      29.91\n74              Rock County      29.69\n75            Murray County      29.60\n76            Isanti County      29.45\n77            Sibley County      28.60\n78            Meeker County      28.58\n79           Redwood County      28.43\n80 Lake of the Woods County      27.87\n81        Clearwater County      26.76\n82         Pipestone County      26.44\n83            Wadena County      26.35\n84            Roseau County      25.98\n85          Marshall County      25.33\n86              Todd County      24.79\n87          Morrison County      22.33\n\n\nPart b\nHere’s my translation:\n\ncounties in Minnesota and Wisconsin —&gt; filter\nchange in Democratic vote percentage in 2020 vs 2016 —&gt; mutate (we don’t already have this)\nsorts the counties from highest to lowest —&gt; arrange\ninclude the following variables (and only these variables) —&gt; select\n\n\n# Remember to try this 1 line at a time before storing!\nmn_wi &lt;- elections_small |&gt; \n  filter(state_name %in% c(\"Minnesota\", \"Wisconsin\")) |&gt; \n  select(state_name, county_name, dem_pct_20, dem_pct_16) |&gt;\n  mutate(dem_change = dem_pct_20 - dem_pct_16) |&gt; \n  arrange(dem_change)\n  \n# Check it out\nhead(mn_wi)\n\n  state_name        county_name dem_pct_20 dem_pct_16 dem_change\n1  Minnesota     Stevens County      37.80      39.55      -1.75\n2  Wisconsin      Forest County      34.06      35.12      -1.06\n3  Wisconsin    Kewaunee County      32.87      33.73      -0.86\n4  Wisconsin       Clark County      30.37      31.19      -0.82\n5  Wisconsin       Adams County      36.63      37.40      -0.77\n6  Wisconsin Trempealeau County      40.86      41.57      -0.71\n\n\nPart c\nThere was a stronger Dem shift from 2016 to 2020 in Minnesota. Further, in most counties across both states, the percent Dem tended to be higher in 2020 than in 2016.\n\nggplot(mn_wi, aes(x = dem_change, fill = state_name)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n\nggplot(mn_wi, aes(y = dem_change, x = state_name)) + \n  geom_boxplot()\n\n\n\n\n\n\n\nExercise 7: summarize Demo\n\n# Calculate the median Repub vote percentage in 2020 across all counties\nelections_small |&gt; \n  summarize(median(repub_pct_20))\n\n  median(repub_pct_20)\n1                68.29\n\n\n\n# Calculate the median Repub vote percentage in 2020 across all counties\n# AND name it \"median_repub\"\nelections_small |&gt; \n  summarize(median_repub = median(repub_pct_20))\n\n  median_repub\n1        68.29\n\n\n\n# Calculate the median Repub vote percentage in 2020 across all counties\n# AND the total number of votes across all counties\n# AND name the results\nelections_small |&gt; \n  summarize(median_repub = median(repub_pct_20), total_votes = sum(total_votes_20))\n\n  median_repub total_votes\n1        68.29   157949293\n\n\nExercise 8: summarize + group_by demo\n\n# Calculate the median 2020 Repub percent and total votes BY STATE\nelections_small |&gt; \n  group_by(state_name) |&gt; \n  summarize(median_repub = median(repub_pct_20), total_votes = sum(total_votes_20)) \n\n# A tibble: 50 × 3\n   state_name           median_repub total_votes\n   &lt;chr&gt;                       &lt;dbl&gt;       &lt;int&gt;\n 1 Alabama                      70.6     2323304\n 2 Arizona                      57.9     3387326\n 3 Arkansas                     72.1     1219069\n 4 California                   44.8    17495906\n 5 Colorado                     56.2     3256953\n 6 Connecticut                  41.0     1824280\n 7 Delaware                     47.1      504010\n 8 District of Columbia          5.4      344356\n 9 Florida                      64.6    11067456\n10 Georgia                      68       4997716\n# ℹ 40 more rows\n\n\nExercise 9: DIY\nPart a\n\n# Sort the states from the most to least total votes in 2020\nelections_small |&gt; \n  group_by(state_name) |&gt; \n  summarize(total = sum(total_votes_20)) |&gt; \n  arrange(desc(total))\n\n# A tibble: 50 × 2\n   state_name        total\n   &lt;chr&gt;             &lt;int&gt;\n 1 California     17495906\n 2 Texas          11317911\n 3 Florida        11067456\n 4 New York        8616205\n 5 Pennsylvania    6925255\n 6 Illinois        6038850\n 7 Ohio            5922202\n 8 Michigan        5539302\n 9 North Carolina  5524801\n10 Georgia         4997716\n# ℹ 40 more rows\n\n\n\n# In 2020, what were the total number of votes for the Democratic candidate and the total number of votes for the Republican candidate in each *state*?\nelections_small |&gt; \n  mutate(dem_votes_20 = round(total_votes_20 * dem_pct_20 / 100), \n         repub_votes_20 = round(total_votes_20 * repub_pct_20 / 100)) |&gt; \n  group_by(state_name) |&gt; \n  summarize(dem_total = sum(dem_votes_20),\n            repub_total = sum(repub_votes_20))\n\n# A tibble: 50 × 3\n   state_name           dem_total repub_total\n   &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Alabama                 849664     1441155\n 2 Arizona                1672127     1661671\n 3 Arkansas                423919      760641\n 4 California            11109642     6006031\n 5 Colorado               1804393     1364627\n 6 Connecticut            1080677      715315\n 7 Delaware                296274      200601\n 8 District of Columbia    317324       18595\n 9 Florida                5297131     5668600\n10 Georgia                2473661     2461869\n# ℹ 40 more rows\n\n\n\n# What states did the Democratic candidate win in 2020?\nelections_small |&gt; \n  mutate(dem_votes_20 = round(total_votes_20 * dem_pct_20 / 100), \n         repub_votes_20 = round(total_votes_20 * repub_pct_20 / 100)) |&gt; \n  group_by(state_name) |&gt; \n  summarize(dem_total = sum(dem_votes_20),\n            repub_total = sum(repub_votes_20)) |&gt; \n  filter(dem_total &gt; repub_total)\n\n# A tibble: 26 × 3\n   state_name           dem_total repub_total\n   &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Arizona                1672127     1661671\n 2 California            11109642     6006031\n 3 Colorado               1804393     1364627\n 4 Connecticut            1080677      715315\n 5 Delaware                296274      200601\n 6 District of Columbia    317324       18595\n 7 Georgia                2473661     2461869\n 8 Hawaii                  366121      196865\n 9 Illinois               3471916     2446931\n10 Maine                   430466      359897\n# ℹ 16 more rows\n\n\nExercise 10: Practice on New Data\n\n# In what years did Brazil win the World Cup?\nworld_cup |&gt; \n  filter(winner == \"Brazil\")\n\n  year               host winner         second        third       fourth\n1 1958             Sweden Brazil         Sweden       France West Germany\n2 1962              Chile Brazil Czechoslovakia        Chile   Yugoslavia\n3 1970             Mexico Brazil          Italy West Germany      Uruguay\n4 1994                USA Brazil          Italy       Sweden     Bulgaria\n5 2002 Japan, South Korea Brazil        Germany       Turkey  South Korea\n  goals_scored teams games attendance\n1          126    16    35     868000\n2           89    16    32     776000\n3           95    16    32    1673975\n4          141    24    52    3568567\n5          161    32    64    2724604\n\n\n\n# What were the 6 World Cups with the highest attendance?\nworld_cup |&gt; \n  arrange(desc(attendance)) |&gt; \n  head()\n\n  year               host  winner    second       third      fourth\n1 1994                USA  Brazil     Italy      Sweden    Bulgaria\n2 2014             Brazil Germany Argentina Netherlands      Brazil\n3 2006            Germany   Italy    France     Germany    Portugal\n4 2018             Russia  France   Croatia     Belgium     England\n5 1998             France  France    Brazil     Croatia Netherlands\n6 2002 Japan, South Korea  Brazil   Germany      Turkey South Korea\n  goals_scored teams games attendance\n1          141    24    52    3568567\n2          171    32    64    3441450\n3          147    32    64    3367000\n4          169    32    64    3031768\n5          171    32    64    2859234\n6          161    32    64    2724604\n\n\n\n# Construct a univariate plot of goals_scored (no wrangling necessary)\n# This provides a visual summary of how the number of goals_scored varies from World Cup to World Cup\nggplot(world_cup, aes(x = goals_scored)) + \n  geom_histogram(color = \"white\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n# Let's follow up the plot with some more precise numerical summaries\n# Calculate the min, median, and max number of goals_scored across all World Cups\n# NOTE: Visually compare these numerical summaries to what you observed in the plot\nworld_cup |&gt; \n  summarize(min(goals_scored), median(goals_scored), max(goals_scored))\n\n  min(goals_scored) median(goals_scored) max(goals_scored)\n1                70                  126               171\n\n\n\n# Construct a bivariate plot of how the number of goals_scored in the World Cup has changed over the years\n# No wrangling necessary\nggplot(world_cup, aes(x = year, y = goals_scored)) + \n  geom_point() + \n  geom_line()\n\n\n\n\n\n\n\n\n# Our above summaries might be a bit misleading.\n# The number of games played at the World Cup varies.\n# Construct a bivariate plot of how the typical number of goals per game has changed over the years\nper_game_data &lt;- world_cup |&gt; \n  mutate(goals_per_game = goals_scored / games)\n\nggplot(per_game_data, aes(x = year, y = goals_per_game)) + \n  geom_point() + \n  geom_line()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Wrangling</span>"
    ]
  },
  {
    "objectID": "ica/ica-date.html",
    "href": "ica/ica-date.html",
    "title": "\n18  Dates\n",
    "section": "",
    "text": "18.1 Exercises Part 1: Same Verbs, New Tricks",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "ica/ica-date.html#exercises-part-1-same-verbs-new-tricks",
    "href": "ica/ica-date.html#exercises-part-1-same-verbs-new-tricks",
    "title": "\n18  Dates\n",
    "section": "",
    "text": "Exercise 1: More Filtering\nRecall the “logical comparison operators” we can use to filter() our data:\n\n\nsymbol\nmeaning\n\n\n\n==\nequal to\n\n\n!=\nnot equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n%in% c(***, ***)\na list of multiple values\n\n\n\nPart a\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npenguins &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv')\n\nRows: 344 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nCommenting/Uncommenting Code\n\n\n\nTo comment/uncomment several lines of code at once, highlight them then click ctrl/cmd+shift+c.\n\n\n\n# Create a dataset with just Adelie and Chinstrap using %in%\n# Pipe this into `count(species)` to confirm that you only have these 2 species\npenguins |&gt; \n   filter(species %in% c(\"Adelie\", \"Chinstrap\")) |&gt; \n   count(species)\n\n# A tibble: 2 × 2\n  species       n\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n\n\n\n# Create a dataset with just Adelie and Chinstrap using !=\n# Pipe this into `count(species)` to confirm that you only have these 2 species\npenguins |&gt; \n filter(species != \"Gentoo\") |&gt; \n   count(species)\n\n# A tibble: 2 × 2\n  species       n\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n\n\nPart b\nNotice that some of our penguins have missing (NA) data on some values:\n\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n\n\n\n\n\n\n\nHandeling NA Values\n\n\n\nThere are many ways to handle missing data. The right approach depends upon your research goals. A general rule is: Only get rid of observations with missing data if they’re missing data on variables you need for the specific task at hand!\n\n\nExample 1\nSuppose our research focus is just on body_mass_g. Two penguins are missing this info:\n\n# NOTE the use of is.na()\npenguins |&gt; \n  summarize(sum(is.na(body_mass_g)))\n\n# A tibble: 1 × 1\n  `sum(is.na(body_mass_g))`\n                      &lt;int&gt;\n1                         2\n\n\nLet’s define a new dataset that removes these penguins:\n\n# NOTE the use of is.na()\npenguins_w_body_mass &lt;- penguins |&gt; \n  filter(!is.na(body_mass_g))\n\n# Compare the number of penguins in this vs the original data\nnrow(penguins_w_body_mass)\n\n[1] 342\n\nnrow(penguins)\n\n[1] 344\n\n\nNote that some penguins in penguins_w_body_mass are missing info on sex, but we don’t care since that’s not related to our research question:\n\npenguins_w_body_mass |&gt; \n  summarize(sum(is.na(sex)))\n\n# A tibble: 1 × 1\n  `sum(is.na(sex))`\n              &lt;int&gt;\n1                 9\n\n\nExample 2\nIn the very rare case that we need complete information on every variable for the specific task at hand, we can use na.omit() to get rid of any penguin that’s missing info on any variable:\n\npenguins_complete &lt;- penguins |&gt; \n  na.omit()\n\nHow many penguins did this eliminate?\n\nnrow(penguins_complete)\n\n[1] 333\n\nnrow(penguins)\n\n[1] 344\n\n\n11 penguins!\nPart c\nExplain why we should only use na.omit() in extreme circumstances.\n\nBecause it indiscriminately removes all the data with n/as in it, when sometimes the specific n/as present won’t matter for your research question\nExercise 2: More Selecting\nBeing able to select() only certain columns can help simplify our data. This is especially important when we’re working with lots of columns (which we haven’t done yet). It can also get tedious to type out every column of interest. Here are some shortcuts:\n\n\n- removes a given variable and keeps all others (e.g. select(-island))\n\nstarts_with(\"___\"), ends_with(\"___\"), or contains(\"___\") selects only the columns that either start with, end with, or simply contain the given string of characters\n\nUse these shortcuts to create the following datasets.\n\n# First: recall the variable names\nnames(penguins)\n\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\n\n\n# Use a shortcut to keep everything but the year and island variables\n\npenguins |&gt;\n  select(-one_of(\"year\", \"island\"))\n\n# A tibble: 344 × 6\n   species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt; \n 1 Adelie            39.1          18.7               181        3750 male  \n 2 Adelie            39.5          17.4               186        3800 female\n 3 Adelie            40.3          18                 195        3250 female\n 4 Adelie            NA            NA                  NA          NA &lt;NA&gt;  \n 5 Adelie            36.7          19.3               193        3450 female\n 6 Adelie            39.3          20.6               190        3650 male  \n 7 Adelie            38.9          17.8               181        3625 female\n 8 Adelie            39.2          19.6               195        4675 male  \n 9 Adelie            34.1          18.1               193        3475 &lt;NA&gt;  \n10 Adelie            42            20.2               190        4250 &lt;NA&gt;  \n# ℹ 334 more rows\n\n\n\n# Use a shortcut to keep only species and the penguin characteristics measured in mm\n\npenguins |&gt;\n  select(one_of(\"species\", \"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"))\n\n# A tibble: 344 × 4\n   species bill_length_mm bill_depth_mm flipper_length_mm\n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n 1 Adelie            39.1          18.7               181\n 2 Adelie            39.5          17.4               186\n 3 Adelie            40.3          18                 195\n 4 Adelie            NA            NA                  NA\n 5 Adelie            36.7          19.3               193\n 6 Adelie            39.3          20.6               190\n 7 Adelie            38.9          17.8               181\n 8 Adelie            39.2          19.6               195\n 9 Adelie            34.1          18.1               193\n10 Adelie            42            20.2               190\n# ℹ 334 more rows\n\n\n\n# Use a shortcut to keep only species and bill-related measurements\n\npenguins |&gt;\n  select(one_of(\"species\", \"bill_length_mm\", \"bill_depth_mm\"))\n\n# A tibble: 344 × 3\n   species bill_length_mm bill_depth_mm\n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n 1 Adelie            39.1          18.7\n 2 Adelie            39.5          17.4\n 3 Adelie            40.3          18  \n 4 Adelie            NA            NA  \n 5 Adelie            36.7          19.3\n 6 Adelie            39.3          20.6\n 7 Adelie            38.9          17.8\n 8 Adelie            39.2          19.6\n 9 Adelie            34.1          18.1\n10 Adelie            42            20.2\n# ℹ 334 more rows\n\n\n\n# Use a shortcut to keep only species and the length-related characteristics\n\npenguins |&gt;\n  select(one_of(\"species\", \"bill_length_mm\", \"flipper_length_mm\"))\n\n# A tibble: 344 × 3\n   species bill_length_mm flipper_length_mm\n   &lt;chr&gt;            &lt;dbl&gt;             &lt;dbl&gt;\n 1 Adelie            39.1               181\n 2 Adelie            39.5               186\n 3 Adelie            40.3               195\n 4 Adelie            NA                  NA\n 5 Adelie            36.7               193\n 6 Adelie            39.3               190\n 7 Adelie            38.9               181\n 8 Adelie            39.2               195\n 9 Adelie            34.1               193\n10 Adelie            42                 190\n# ℹ 334 more rows\n\n\n\nExercise 3: Arranging, Counting, & Grouping by Multiple Variables\nWe’ve done examples where we need to filter() by more than one variable, or select() more than one variable. Use your intuition for how we can arrange(), count(), and group_by() more than one variable.\n\n# Change this code to sort the penguins by species, and then island name\n# NOTE: The first row should be an Adelie penguin living on Biscoe island\npenguins |&gt; \n  arrange(species, island)\n\n# A tibble: 344 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Adelie  Biscoe           37.8          18.3               174        3400\n 2 Adelie  Biscoe           37.7          18.7               180        3600\n 3 Adelie  Biscoe           35.9          19.2               189        3800\n 4 Adelie  Biscoe           38.2          18.1               185        3950\n 5 Adelie  Biscoe           38.8          17.2               180        3800\n 6 Adelie  Biscoe           35.3          18.9               187        3800\n 7 Adelie  Biscoe           40.6          18.6               183        3550\n 8 Adelie  Biscoe           40.5          17.9               187        3200\n 9 Adelie  Biscoe           37.9          18.6               172        3150\n10 Adelie  Biscoe           40.5          18.9               180        3950\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n\n\n# Change this code to count the number of male/female penguins observed for each species\npenguins |&gt; \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n\n\n# Change this code to calculate the average body mass by species and sex\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(mean = mean(body_mass_g, na.rm = TRUE))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex     mean\n  &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie    female 3369.\n2 Adelie    male   4043.\n3 Adelie    &lt;NA&gt;   3540 \n4 Chinstrap female 3527.\n5 Chinstrap male   3939.\n6 Gentoo    female 4680.\n7 Gentoo    male   5485.\n8 Gentoo    &lt;NA&gt;   4588.\n\n\n\nExercise 4: Dates\nBefore some wrangling practice, let’s explore another important concept: working with or mutating date variables. Dates are a whole special object type or class in R that automatically respect the order of time.\n\n# Get today's date\nas.Date(today())\n\n[1] \"2025-04-05\"\n\n# Let's store this as \"today\" so we can work with it below\ntoday &lt;- as.Date(today())\n\n# Check out the class of this object\nclass(today)\n\n[1] \"Date\"\n\n\nThe lubridate package inside tidyverse contains functions that can extract various information from dates. Let’s learn about some of the most common functions by applying them to today. For each, make a comment on what the function does\n\n#gives the current year\nyear(today)\n\n[1] 2025\n\n\n\n# What do these lines produce / what's their difference?\n\n#gives today's month in numerical form\nmonth(today)\n\n[1] 4\n\n#gives the name of today's month (abbreviated)\nmonth(today, label = TRUE)\n\n[1] Apr\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\n\n\n# What does this number mean?\n\n#this is the week of 2025 we are on currently\nweek(today)\n\n[1] 14\n\n\n\n# What do these lines produce / what's their difference?\n\n#number of days into the month we are\nmday(today)\n\n[1] 5\n\n#number of days into the year we are\nyday(today)  # This is often called the \"Julian day\"\n\n[1] 95\n\n\n\n# What do these lines produce / what's their difference?\n\n#number day of the week we're on (starting from sunday)\nwday(today)\n\n[1] 7\n\n#day of the week we're on (with labels)\nwday(today, label = TRUE)\n\n[1] Sat\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\n\n\n# What do the results of these 2 lines tell us?\n\n#the first line is asking if today's date is greater or equal to feb 14th 2024, which it is, so it returns true\ntoday &gt;= ymd(\"2024-02-14\")\n\n[1] TRUE\n\n#the second line is asking if today's date is less than feb 14th 2024, which it is not, so it returns false\ntoday &lt; ymd(\"2024-02-14\")\n\n[1] FALSE",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "ica/ica-date.html#exercises-part-2-application",
    "href": "ica/ica-date.html#exercises-part-2-application",
    "title": "\n18  Dates\n",
    "section": "\n18.2 Exercises Part 2: Application",
    "text": "18.2 Exercises Part 2: Application\nThe remaining exercises are similar to some of those on the homework. Hence, the solutions are not provided. Let’s apply these ideas to the daily Birthdays dataset in the mosaic package.\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\ndata(\"Birthdays\")\nhead(Birthdays)\n\n  state year month day       date wday births\n1    AK 1969     1   1 1969-01-01  Wed     14\n2    AL 1969     1   1 1969-01-01  Wed    174\n3    AR 1969     1   1 1969-01-01  Wed     78\n4    AZ 1969     1   1 1969-01-01  Wed     84\n5    CA 1969     1   1 1969-01-01  Wed    824\n6    CO 1969     1   1 1969-01-01  Wed    100\n\n\nBirthdays gives the number of births recorded on each day of the year in each state from 1969 to 19881. We can use our wrangling skills to understand some drivers of daily births. Putting these all together can be challenging! Remember the following ways to make tasks more manageable:\n\nTranslate the prompt into our 6 verbs (and count()). That is, think before you type.\nBuild your code line by line. It’s important to understand what’s being piped into each function!\n\nExercise 5: Warming up\n\n# How many days of data do we have for each state?\n\nBirthdays |&gt;\n  group_by(state) |&gt;\n  count(\"date\") |&gt;\n  select(state, n)\n\n# A tibble: 51 × 2\n# Groups:   state [51]\n   state     n\n   &lt;chr&gt; &lt;int&gt;\n 1 AK     7306\n 2 AL     7312\n 3 AR     7310\n 4 AZ     7310\n 5 CA     7325\n 6 CO     7305\n 7 CT     7312\n 8 DC     7311\n 9 DE     7307\n10 FL     7307\n# ℹ 41 more rows\n\n# How many total births were there in this time period?\n\nBirthdays |&gt;\n  summarize(sum(births))\n\n  sum(births)\n1    70486538\n\n# How many total births were there per state in this time period, sorted from low to high?\n\nBirthdays |&gt;\n  group_by(state) |&gt;\n  summarize(sum(births)) |&gt;\n  arrange(`sum(births)`)\n\n# A tibble: 51 × 2\n   state `sum(births)`\n   &lt;chr&gt;         &lt;int&gt;\n 1 VT           147886\n 2 WY           154019\n 3 AK           185385\n 4 DE           188705\n 5 SD           235734\n 6 ND           238696\n 7 NV           241470\n 8 MT           253884\n 9 NH           264984\n10 RI           265038\n# ℹ 41 more rows\n\n\nExercise 6: Homework Reprise\nCreate a new dataset named daily_births that includes the total number of births per day (across all states) and the corresponding day of the week, eg, Mon. NOTE: Name the column with total births so that it’s easier to wrangle and plot.\n\ndaily_births &lt;- Birthdays |&gt;\n  group_by(date) |&gt;\n  summarize(total_births = sum(births)) |&gt;\n  mutate(wday = weekdays(date))\n\nUsing this data, construct a plot of births over time, indicating the day of week.\n\nggplot(daily_births, aes(x = date, y = total_births, color = wday)) +\n  geom_point()\n\n\n\n\n\n\n\nExercise 7: Wrangle & Plot\nFor each prompt below, you can decide whether you want to: (1) wrangle and store data, then plot; or (2) wrangle data and pipe directly into ggplot. For example:\n\npenguins |&gt; \n  filter(species != \"Gentoo\") |&gt; \n  ggplot(aes(y = bill_length_mm, x = bill_depth_mm, color = species)) + \n    geom_point()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nPart a\nCalculate the total number of births in each month and year, eg, Jan 1969, Feb 1969, …. Label month by names not numbers, eg, Jan not 1. Then, plot the births by month and comment on what you learn.\n\ndaily_births |&gt;\n  mutate(year = year(date), month = month(date, label = TRUE)) |&gt;\n  group_by(month, year) |&gt;\n  summarize(monthly_births = sum(total_births)) |&gt;\n  ggplot(aes(x = month, y = monthly_births)) +\n  geom_boxplot()\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\nThere seems to be a noticeable peak in the summer/early fall, and a dip in winter/early spring.\nPart b\nIn 1988, calculate the total number of births per week in each state. Get rid of week “53”, which isn’t a complete week! Then, make a line plot of births by week for each state and comment on what you learn. For example, do you notice any seasonal trends? Are these the same in every state? Any outliers?\n\nBirthdays |&gt;\n  mutate(year = year(date), week = week(date)) |&gt;\n  group_by(state, week) |&gt;\n  summarize(weekly_births = sum(births)) |&gt;\n  filter(week != 53) |&gt;\n  ggplot(aes(x = week, y = weekly_births, color = state)) +\n  geom_line()\n\n`summarise()` has grouped output by 'state'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\nPart c\nRepeat the above for just Minnesota (MN) and Louisiana (LA). MN has one of the coldest climates and LA has one of the warmest. How do their seasonal trends compare? Do you think these trends are similar in other colder and warmer states? Try it!\n\nBirthdays |&gt;\n  mutate(year = year(date), week = week(date)) |&gt;\n  filter(week != 53, state %in% c(\"LA\", \"MN\")) |&gt;\n  group_by(state, week) |&gt;\n  summarize(weekly_births = sum(births)) |&gt;\n  ggplot(aes(x = week, y = weekly_births, color = state)) +\n  geom_line()\n\n`summarise()` has grouped output by 'state'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\nMN’s birth rates stay relatively stable except for the beginning and end of the year (winter), LA has much more distinct trends.\nExercise 8: More Practice\nPart a\nCreate a dataset with only births in Massachusetts (MA) in 1979 and sort the days from those with the most births to those with the fewest.\n\nMA_births &lt;- Birthdays |&gt;\n  filter(state == \"MA\", year == \"1979\") |&gt;\n  arrange(desc(births))\n\nPart b\nMake a table showing the five states with the most births between September 9, 1979 and September 12, 1979, including the 9th and 12th. Arrange the table in descending order of births.\n\nBirthdays |&gt;\n  filter(year == \"1979\", month == \"9\", day &gt;=   9, day &lt;= 12) |&gt;\n  arrange(desc(births)) |&gt;\n  head(5)\n\n  state year month day       date wday births\n1    CA 1979     9  12 1979-09-12  Wed   1176\n2    CA 1979     9  11 1979-09-11 Tues   1170\n3    CA 1979     9  10 1979-09-10  Mon   1108\n4    CA 1979     9   9 1979-09-09  Sun    968\n5    TX 1979     9  11 1979-09-11 Tues    845",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "ica/ica-date.html#solutions",
    "href": "ica/ica-date.html#solutions",
    "title": "\n18  Dates\n",
    "section": "\n18.3 Solutions",
    "text": "18.3 Solutions\n\nClick for Solutions\nExample 1: Single Verb\n\nggplot(penguins, aes(y = body_mass_g, x = bill_length_mm, color = species)) + \n  geom_point() + \n  facet_wrap(~ sex)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n# Get data on only Adelie penguins that weigh more than 4700g\npenguins |&gt; \n  filter(species == \"Adelie\", body_mass_g &gt; 4700)\n\n# A tibble: 2 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Biscoe           41              20               203        4725\n2 Adelie  Biscoe           43.2            19               197        4775\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n# Get data on penguin body mass only\n# Show just the first 6 rows\npenguins |&gt; \n  select(body_mass_g) |&gt; \n  head()\n\n# A tibble: 6 × 1\n  body_mass_g\n        &lt;dbl&gt;\n1        3750\n2        3800\n3        3250\n4          NA\n5        3450\n6        3650\n\n# Sort the penguins from smallest to largest body mass\n# Show just the first 6 rows\npenguins |&gt; \n  arrange(body_mass_g) |&gt; \n  head()\n\n# A tibble: 6 × 8\n  species   island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Chinstrap Dream               46.9          16.6               192        2700\n2 Adelie    Biscoe              36.5          16.6               181        2850\n3 Adelie    Biscoe              36.4          17.1               184        2850\n4 Adelie    Biscoe              34.5          18.1               187        2900\n5 Adelie    Dream               33.1          16.1               178        2900\n6 Adelie    Torgersen           38.6          17                 188        2900\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n# Calculate the average body mass across all penguins\n# Note: na.rm = TRUE removes the NAs from the calculation\npenguins |&gt; \n  summarize(mean = mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 1 × 1\n   mean\n  &lt;dbl&gt;\n1 4202.\n\n# Calculate the average body mass by species\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(mean = mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 3 × 2\n  species    mean\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Adelie    3701.\n2 Chinstrap 3733.\n3 Gentoo    5076.\n\n# Create a new column that records body mass in kilograms, not grams\n# NOTE: there are 1000 g in 1 kg\n# Show just the first 6 rows\npenguins |&gt; \n  mutate(body_mass_kg = body_mass_g/1000) |&gt; \n  head()\n\n# A tibble: 6 × 9\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;, body_mass_kg &lt;dbl&gt;\n\n\n\n\nggplot(penguins, aes(x = species)) + \n  geom_bar()\n\n\n\n\n\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(n())\n\n# A tibble: 3 × 2\n  species   `n()`\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\npenguins |&gt; \n  count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nExample 2: Multiple Verbs\n\n# Sort Gentoo penguins from biggest to smallest with respect to their \n# bill length in cm (there are 10 mm in a cm)\npenguins |&gt; \n  filter(species == \"Gentoo\") |&gt; \n  mutate(bill_length_cm = bill_length_mm / 10) |&gt; \n  arrange(desc(bill_length_cm))\n\n# A tibble: 124 × 9\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Gentoo  Biscoe           59.6          17                 230        6050\n 2 Gentoo  Biscoe           55.9          17                 228        5600\n 3 Gentoo  Biscoe           55.1          16                 230        5850\n 4 Gentoo  Biscoe           54.3          15.7               231        5650\n 5 Gentoo  Biscoe           53.4          15.8               219        5500\n 6 Gentoo  Biscoe           52.5          15.6               221        5450\n 7 Gentoo  Biscoe           52.2          17.1               228        5400\n 8 Gentoo  Biscoe           52.1          17                 230        5550\n 9 Gentoo  Biscoe           51.5          16.3               230        5500\n10 Gentoo  Biscoe           51.3          14.2               218        5300\n# ℹ 114 more rows\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;, bill_length_cm &lt;dbl&gt;\n\n# Sort the species from smallest to biggest with respect to their \n# average bill length in cm\npenguins |&gt; \n  mutate(bill_length_cm = bill_length_mm / 10) |&gt; \n  group_by(species) |&gt; \n  summarize(mean_bill_length = mean(bill_length_cm, na.rm = TRUE)) |&gt; \n  arrange(desc(mean_bill_length))\n\n# A tibble: 3 × 2\n  species   mean_bill_length\n  &lt;chr&gt;                &lt;dbl&gt;\n1 Chinstrap             4.88\n2 Gentoo                4.75\n3 Adelie                3.88\n\n\nExample 3: Interpret Code\nExercise 1: More Filtering\nPart a\n\n# Create a dataset with just Adelie and Chinstrap using %in%\n# Pipe this into `count(species)` to confirm that you only have these 2 species\npenguins |&gt;\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) |&gt;\n  count(species)\n\n# A tibble: 2 × 2\n  species       n\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n\n\n\n# Create a dataset with just Adelie and Chinstrap using !=\n# Pipe this into `count(species)` to confirm that you only have these 2 species\npenguins |&gt;\n  filter(species != \"Gentoo\") |&gt;\n  count(species)\n\n# A tibble: 2 × 2\n  species       n\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n\n\nPart b\nPart c\nIt might get rid of data points even if they have complete information on the variables we need, just because they’re missing info on variables we don’t need.\nExercise 2: More selecting\n\n# First: recall the variable names\nnames(penguins)\n\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\n\n\n# Use a shortcut to keep everything but the year and island variables\npenguins |&gt; \n  select(-year, -island)\n\n# A tibble: 344 × 6\n   species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt; \n 1 Adelie            39.1          18.7               181        3750 male  \n 2 Adelie            39.5          17.4               186        3800 female\n 3 Adelie            40.3          18                 195        3250 female\n 4 Adelie            NA            NA                  NA          NA &lt;NA&gt;  \n 5 Adelie            36.7          19.3               193        3450 female\n 6 Adelie            39.3          20.6               190        3650 male  \n 7 Adelie            38.9          17.8               181        3625 female\n 8 Adelie            39.2          19.6               195        4675 male  \n 9 Adelie            34.1          18.1               193        3475 &lt;NA&gt;  \n10 Adelie            42            20.2               190        4250 &lt;NA&gt;  \n# ℹ 334 more rows\n\n\n\n# Use a shortcut to keep only species and the penguin characteristics measured in mm\npenguins |&gt; \n  select(species, ends_with(\"mm\"))\n\n# A tibble: 344 × 4\n   species bill_length_mm bill_depth_mm flipper_length_mm\n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n 1 Adelie            39.1          18.7               181\n 2 Adelie            39.5          17.4               186\n 3 Adelie            40.3          18                 195\n 4 Adelie            NA            NA                  NA\n 5 Adelie            36.7          19.3               193\n 6 Adelie            39.3          20.6               190\n 7 Adelie            38.9          17.8               181\n 8 Adelie            39.2          19.6               195\n 9 Adelie            34.1          18.1               193\n10 Adelie            42            20.2               190\n# ℹ 334 more rows\n\n\n\n# Use a shortcut to keep only species and bill-related measurements\npenguins |&gt; \n  select(species, starts_with(\"bill\"))\n\n# A tibble: 344 × 3\n   species bill_length_mm bill_depth_mm\n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n 1 Adelie            39.1          18.7\n 2 Adelie            39.5          17.4\n 3 Adelie            40.3          18  \n 4 Adelie            NA            NA  \n 5 Adelie            36.7          19.3\n 6 Adelie            39.3          20.6\n 7 Adelie            38.9          17.8\n 8 Adelie            39.2          19.6\n 9 Adelie            34.1          18.1\n10 Adelie            42            20.2\n# ℹ 334 more rows\n\n\n\n# Use a shortcut to keep only species and the length-related characteristics\npenguins |&gt; \n  select(species, contains(\"length\"))\n\n# A tibble: 344 × 3\n   species bill_length_mm flipper_length_mm\n   &lt;chr&gt;            &lt;dbl&gt;             &lt;dbl&gt;\n 1 Adelie            39.1               181\n 2 Adelie            39.5               186\n 3 Adelie            40.3               195\n 4 Adelie            NA                  NA\n 5 Adelie            36.7               193\n 6 Adelie            39.3               190\n 7 Adelie            38.9               181\n 8 Adelie            39.2               195\n 9 Adelie            34.1               193\n10 Adelie            42                 190\n# ℹ 334 more rows\n\n\nExercise 3: Arranging, counting, & grouping by multiple variables\n\n# Change this code to sort the penguins by species, and then island name\n# NOTE: The first row should be an Adelie penguin living on Biscoe island\npenguins |&gt; \n  arrange(species, island) |&gt; \n  head()\n\n# A tibble: 6 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Biscoe           37.8          18.3               174        3400\n2 Adelie  Biscoe           37.7          18.7               180        3600\n3 Adelie  Biscoe           35.9          19.2               189        3800\n4 Adelie  Biscoe           38.2          18.1               185        3950\n5 Adelie  Biscoe           38.8          17.2               180        3800\n6 Adelie  Biscoe           35.3          18.9               187        3800\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n\n\n# Change this code to count the number of male/female penguins observed for each species\npenguins |&gt; \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n\n\n# Change this code to calculate the average body mass by species and sex\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(mean = mean(body_mass_g, na.rm = TRUE))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex     mean\n  &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie    female 3369.\n2 Adelie    male   4043.\n3 Adelie    &lt;NA&gt;   3540 \n4 Chinstrap female 3527.\n5 Chinstrap male   3939.\n6 Gentoo    female 4680.\n7 Gentoo    male   5485.\n8 Gentoo    &lt;NA&gt;   4588.\n\n\nExercise 4: Dates\n\n# Get today's date\nas.Date(today())\n\n[1] \"2025-04-05\"\n\n# Let's store this as \"today\" so we can work with it below\ntoday &lt;- as.Date(today())\n\n# Check out the class of this object\nclass(today)\n\n[1] \"Date\"\n\n\n\n# Records just the 4-digit year\nyear(today)\n\n[1] 2025\n\n\n\n# Today's month, as a number or label\nmonth(today)\n\n[1] 4\n\nmonth(today, label = TRUE)\n\n[1] Apr\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\n\n\n# This is the week of the year (1-52)\nweek(today)\n\n[1] 14\n\n\n\n# Day of the month (1-31) and day of the year (1-366)\nmday(today)\n\n[1] 5\n\nyday(today)  # This is often called the \"Julian day\"\n\n[1] 95\n\n\n\n# Day of the week as a number or label\nwday(today)\n\n[1] 7\n\nwday(today, label = TRUE)\n\n[1] Sat\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\n\n\n# today is on or after Feb 14, 2024\ntoday &gt;= ymd(\"2024-02-14\")\n\n[1] TRUE\n\n# today is not before Feb 14, 2024\ntoday &lt; ymd(\"2024-02-14\")\n\n[1] FALSE",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "ica/ica-date.html#footnotes",
    "href": "ica/ica-date.html#footnotes",
    "title": "\n18  Dates\n",
    "section": "",
    "text": "The fivethirtyeight package has more recent data.↩︎",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html",
    "href": "ica/ica-reshaping.html",
    "title": "\n19  Reshaping\n",
    "section": "",
    "text": "Exercise 1: What’s the problem?\nConsider data on a sleep study in which subjects received only 3 hours of sleep per night. Each day, their reaction time to a stimulus (in ms) was recorded.1\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npenguins &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv')\n\nRows: 344 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsleep_wide &lt;- read.csv(\"https://mac-stat.github.io/data/sleep_wide.csv\")\n\nhead(sleep_wide)\n\n  Subject  day_0  day_1  day_2  day_3  day_4  day_5  day_6  day_7  day_8  day_9\n1     308 249.56 258.70 250.80 321.44 356.85 414.69 382.20 290.15 430.59 466.35\n2     309 222.73 205.27 202.98 204.71 207.72 215.96 213.63 217.73 224.30 237.31\n3     310 199.05 194.33 234.32 232.84 229.31 220.46 235.42 255.75 261.01 247.52\n4     330 321.54 300.40 283.86 285.13 285.80 297.59 280.24 318.26 305.35 354.05\n5     331 287.61 285.00 301.82 320.12 316.28 293.32 290.08 334.82 293.75 371.58\n6     332 234.86 242.81 272.96 309.77 317.46 310.00 454.16 346.83 330.30 253.86",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#solutions",
    "href": "ica/ica-reshaping.html#solutions",
    "title": "\n19  Reshaping\n",
    "section": "\n19.1 Solutions",
    "text": "19.1 Solutions\n\nClick for Solutions\nEXAMPLE 1: warm-up counts and proportions\n\n# Using count()\npenguins |&gt; \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n# Using group_by() and summarize()\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(n())\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex    `n()`\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n# Relative frequencies\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(n = n()) |&gt; \n  mutate(proportion = n / sum(n))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 4\n# Groups:   species [3]\n  species   sex        n proportion\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie    female    73     0.480 \n2 Adelie    male      73     0.480 \n3 Adelie    &lt;NA&gt;       6     0.0395\n4 Chinstrap female    34     0.5   \n5 Chinstrap male      34     0.5   \n6 Gentoo    female    58     0.468 \n7 Gentoo    male      61     0.492 \n8 Gentoo    &lt;NA&gt;       5     0.0403\n\n# Changing the order calculates the proportion of species within each sex\npenguins |&gt; \n  group_by(sex, species) |&gt; \n  summarize(n = n()) |&gt; \n  mutate(proportion = n / sum(n))\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 8 × 4\n# Groups:   sex [3]\n  sex    species       n proportion\n  &lt;chr&gt;  &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n1 female Adelie       73      0.442\n2 female Chinstrap    34      0.206\n3 female Gentoo       58      0.352\n4 male   Adelie       73      0.435\n5 male   Chinstrap    34      0.202\n6 male   Gentoo       61      0.363\n7 &lt;NA&gt;   Adelie        6      0.545\n8 &lt;NA&gt;   Gentoo        5      0.455\n\n\nEXAMPLE 3: units of observation\n\n# Units of observation = penguins\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\npenguin_avg &lt;- penguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(avg_body_mass = mean(body_mass_g, na.rm = TRUE)) |&gt; \n  na.omit()\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n# Units of observation = species/sex combos\nhead(penguin_avg)\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\nEXAMPLE 5: pivot wider\n\npenguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass)\n\n# A tibble: 3 × 3\n# Groups:   species [3]\n  species   female  male\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.\n2 Chinstrap  3527. 3939.\n3 Gentoo     4680. 5485.\n\n\nFOLLOW-UP:\n\nWhat are the units of observation? species\nDid we lose any information when we widened the data? no\nUse the wide data to calculate the difference in average body mass, male vs female, for each species.\n\n\npenguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass) |&gt; \n  mutate(diff = male - female)\n\n# A tibble: 3 × 4\n# Groups:   species [3]\n  species   female  male  diff\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     3369. 4043.  675.\n2 Chinstrap  3527. 3939.  412.\n3 Gentoo     4680. 5485.  805.\n\n\nEXAMPLE 6: Pivot longer\n\npenguin_avg_wide &lt;- penguin_avg |&gt; \n  pivot_wider(names_from = sex, values_from = avg_body_mass)\n\n# We can either communicate which variables we WANT to collect into a single column (female, male)\npenguin_avg_wide |&gt; \n  pivot_longer(cols = c(female, male), names_to = \"sex\", values_to = \"avg_body_mass\")\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n# Or which variable(s) we do NOT want to collect into a single column (sex)\npenguin_avg_wide |&gt; \n  pivot_longer(cols = -species, names_to = \"sex\", values_to = \"avg_body_mass\")\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485.\n\n\nFOLLOW-UP:\n\nWhat are the units of observation? species/sex combos\nDid we lose any information when we lengthened the data? no\n\n19.1.1 EXAMPLE 7: Practice [-]\n\nfood &lt;- data.frame(\n  customer = rep(c(\"A\", \"B\"), each = 3),\n  restaurant = rep(c(\"Shish\", \"FrenchMeadow\", \"DunnBros\"), 2),\n  order = c(\"falafel\", \"salad\", \"coffee\", \"baklava\", \"pastry\", \"tea\")\n)\n\nfood\n\n  customer   restaurant   order\n1        A        Shish falafel\n2        A FrenchMeadow   salad\n3        A     DunnBros  coffee\n4        B        Shish baklava\n5        B FrenchMeadow  pastry\n6        B     DunnBros     tea\n\nfood |&gt; \n  pivot_wider(names_from = restaurant, values_from = order)\n\n# A tibble: 2 × 4\n  customer Shish   FrenchMeadow DunnBros\n  &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;   \n1 A        falafel salad        coffee  \n2 B        baklava pastry       tea     \n\n\n\nmore_food &lt;- data.frame(\n  customer = c(\"C\", \"D\"),\n  Shish = c(\"coffee\", \"maza\"),\n  FrenchMeadow = c(\"soup\", \"sandwich\"),\n  DunnBros = c(\"cookie\", \"coffee\")\n)\n\nmore_food\n\n  customer  Shish FrenchMeadow DunnBros\n1        C coffee         soup   cookie\n2        D   maza     sandwich   coffee\n\nmore_food |&gt; \n  pivot_longer(cols = -customer, names_to = \"restaurant\", values_to = \"order\")\n\n# A tibble: 6 × 3\n  customer restaurant   order   \n  &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;   \n1 C        Shish        coffee  \n2 C        FrenchMeadow soup    \n3 C        DunnBros     cookie  \n4 D        Shish        maza    \n5 D        FrenchMeadow sandwich\n6 D        DunnBros     coffee  \n\n\nExercise 1: What’s the problem?\nPart a\nsubjects/people\nPart c\npivot_longer()\nExercise 2: Pivot longer\nPart a\n\n# For cols, try 2 appproaches: using - and starts_with\nsleep_wide |&gt;\n  pivot_longer(cols = -Subject, names_to = \"day\", values_to = \"reaction_time\")\n\n# A tibble: 180 × 3\n   Subject day   reaction_time\n     &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1     308 day_0          250.\n 2     308 day_1          259.\n 3     308 day_2          251.\n 4     308 day_3          321.\n 5     308 day_4          357.\n 6     308 day_5          415.\n 7     308 day_6          382.\n 8     308 day_7          290.\n 9     308 day_8          431.\n10     308 day_9          466.\n# ℹ 170 more rows\n\nsleep_wide |&gt;\n  pivot_longer(cols = starts_with(\"day\"), names_to = \"day\", values_to = \"reaction_time\")\n\n# A tibble: 180 × 3\n   Subject day   reaction_time\n     &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1     308 day_0          250.\n 2     308 day_1          259.\n 3     308 day_2          251.\n 4     308 day_3          321.\n 5     308 day_4          357.\n 6     308 day_5          415.\n 7     308 day_6          382.\n 8     308 day_7          290.\n 9     308 day_8          431.\n10     308 day_9          466.\n# ℹ 170 more rows\n\n\nPart b\nAdding names_prefix = \"day_\" removed “day_” from the start of the day entries. did this impact how the values are recorded in the day column?\n\nsleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\") \n\nPart c\nSubject is an integer and day is a character. We want them to be categorical (factor) and numeric, respectively.\n\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) + \n  geom_line()\n\n\n\n\n\n\n\nExercise 3: Changing variable classes & plotting\n\nsleep_long &lt;- sleep_wide |&gt;\n  pivot_longer(cols = -Subject,\n               names_to = \"day\",\n               names_prefix = \"day_\",\n               values_to = \"reaction_time\") |&gt; \n  mutate(Subject = as.factor(Subject), day = as.numeric(day))\n\nPart a\nNow make some plots.\n\n# Make a line plot of reaction time by day for each subject\n# Put these all on the same frame\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) + \n  geom_line()\n\n\n\n\n\n\n\n\n# Make a line plot of reaction time by day for each subject\n# Put these all on separate frames (one per subject)\nggplot(sleep_long, aes(y = reaction_time, x = day, color = Subject)) + \n  geom_line() + \n  facet_wrap(~ Subject)\n\n\n\n\n\n\n\nPart b\nReaction time increases (worsens) with a lack of sleep. Some subjects seem to be more impacted than others by lack of sleep, and some tend to have faster/slower reaction times in general.\nExercise 4: Pivot wider\nPart a\n\nsleep_long |&gt;\n  pivot_wider(names_from = day, values_from = reaction_time) |&gt;\n  head()\n\n# A tibble: 6 × 11\n  Subject   `0`   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 308      250.  259.  251.  321.  357.  415.  382.  290.  431.  466.\n2 309      223.  205.  203.  205.  208.  216.  214.  218.  224.  237.\n3 310      199.  194.  234.  233.  229.  220.  235.  256.  261.  248.\n4 330      322.  300.  284.  285.  286.  298.  280.  318.  305.  354.\n5 331      288.  285   302.  320.  316.  293.  290.  335.  294.  372.\n6 332      235.  243.  273.  310.  317.  310   454.  347.  330.  254.\n\n\nPart b\n\nsleep_long |&gt;\n  pivot_wider(names_from = day, values_from = reaction_time, names_prefix = \"day_\") |&gt;\n  head()\n\n# A tibble: 6 × 11\n  Subject day_0 day_1 day_2 day_3 day_4 day_5 day_6 day_7 day_8 day_9\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 308      250.  259.  251.  321.  357.  415.  382.  290.  431.  466.\n2 309      223.  205.  203.  205.  208.  216.  214.  218.  224.  237.\n3 310      199.  194.  234.  233.  229.  220.  235.  256.  261.  248.\n4 330      322.  300.  284.  285.  286.  298.  280.  318.  305.  354.\n5 331      288.  285   302.  320.  316.  293.  290.  335.  294.  372.\n6 332      235.  243.  273.  310.  317.  310   454.  347.  330.  254.\n\n\nExercise 5: Practice with Billboard charts\nPart a\nThe higher a song’s week 1 rating, the higher its week 2 rating tends to be. But almost all song’s rankings drop from week 1 to week 2.\n\nggplot(billboard, aes(y = wk2, x = wk1)) + \n  geom_point() +\n  geom_abline(intercept = 0, slope = 1)\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nPart b\n\nbillboard |&gt; \n  filter(wk2 &gt; wk1)\n\n# A tibble: 7 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Carey, Mar… Cryb… 2000-06-24      28    34    48    62    77    90    95    NA\n2 Clark, Ter… A Li… 2000-12-16      75    82    88    96    99    99    NA    NA\n3 Diffie, Joe The … 2000-01-01      98   100   100    90    93    94    NA    NA\n4 Hart, Beth  L.A.… 1999-11-27      99   100    98    99    99    99    98    90\n5 Jay-Z       Hey … 2000-08-12      98   100    98    94    83    83    80    78\n6 Lil' Zane   Call… 2000-07-29      83    89    57    40    34    21    33    46\n7 Pearl Jam   Noth… 2000-05-13      49    70    84    89    93    91    NA    NA\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, …\n\n\nPart c\n\n# Define nov_1999\nnov_1999 &lt;- billboard |&gt; \n  filter(date.entered == \"1999-11-06\") |&gt; \n  select(-track, -date.entered)\n\n# Or\nnov_1999 &lt;- billboard |&gt; \n  filter(date.entered == \"1999-11-06\") |&gt; \n  select(artist, starts_with(\"wk\"))\n\n\n# Confirm that nov_1999 has 2 rows (songs) and 77 columns\ndim(nov_1999)\n\n[1]  2 77\n\n\nPart c\n\nnov_1999 |&gt; \n  pivot_longer(cols = -artist, names_to = \"week\", names_prefix = \"wk\", values_to = \"ranking\") |&gt; \n  mutate(week = as.numeric(week)) |&gt; \n  ggplot(aes(y = ranking, x = week, color = artist)) + \n    geom_line()\n\nWarning: Removed 79 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\nExercise 6: Practice with the Daily Show\nPart a\n\ndaily |&gt; \n  count(raw_guest_list) |&gt; \n  arrange(desc(n)) |&gt; \n  head(15)\n\n# A tibble: 15 × 2\n   raw_guest_list        n\n   &lt;chr&gt;             &lt;int&gt;\n 1 Fareed Zakaria       19\n 2 Denis Leary          17\n 3 Brian Williams       16\n 4 Paul Rudd            13\n 5 Ricky Gervais        13\n 6 Tom Brokaw           12\n 7 Bill O'Reilly        10\n 8 Reza Aslan           10\n 9 Richard Lewis        10\n10 Will Ferrell         10\n11 Sarah Vowell          9\n12 Adam Sandler          8\n13 Ben Affleck           8\n14 Louis C.K.            8\n15 Maggie Gyllenhaal     8\n\n\nPart b\n\ndaily |&gt; \n  count(year, raw_guest_list) |&gt; \n  group_by(raw_guest_list) |&gt; \n  mutate(total = sum(n)) |&gt;\n  pivot_wider(names_from = year, \n              values_from = n,\n              values_fill = 0) |&gt; \n  arrange(desc(total)) |&gt; \n  head(15)\n\n# A tibble: 15 × 19\n# Groups:   raw_guest_list [15]\n   raw_guest_list  total `1999` `2000` `2001` `2002` `2003` `2004` `2005` `2006`\n   &lt;chr&gt;           &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n 1 Fareed Zakaria     19      0      0      1      0      1      2      2      2\n 2 Denis Leary        17      1      0      1      2      1      0      0      1\n 3 Brian Williams     16      0      0      0      0      1      1      2      1\n 4 Paul Rudd          13      1      0      1      1      1      1      1      0\n 5 Ricky Gervais      13      0      0      0      0      0      0      1      2\n 6 Tom Brokaw         12      0      0      0      1      0      2      1      0\n 7 Richard Lewis      10      1      0      2      2      1      1      0      0\n 8 Will Ferrell       10      0      1      1      0      1      1      1      1\n 9 Bill O'Reilly      10      0      0      1      1      0      1      1      0\n10 Reza Aslan         10      0      0      0      0      0      0      1      2\n11 Sarah Vowell        9      0      0      0      1      0      1      1      1\n12 Adam Sandler        8      1      2      0      1      0      0      0      1\n13 Ben Affleck         8      0      0      0      0      2      0      0      1\n14 Maggie Gyllenh…     8      0      0      0      0      1      0      1      1\n15 Louis C.K.          8      0      0      0      0      0      0      0      1\n# ℹ 9 more variables: `2007` &lt;int&gt;, `2008` &lt;int&gt;, `2009` &lt;int&gt;, `2010` &lt;int&gt;,\n#   `2011` &lt;int&gt;, `2012` &lt;int&gt;, `2013` &lt;int&gt;, `2014` &lt;int&gt;, `2015` &lt;int&gt;\n\n\nPart c\n\nplot_data |&gt;\n  group_by(year, broad_group) |&gt;\n  summarise(n = n()) |&gt;\n  mutate(freq = n / sum(n)) |&gt; \n  ggplot(aes(y = freq, x = year, color = broad_group)) + \n    geom_line()\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-reshaping.html#footnotes",
    "href": "ica/ica-reshaping.html#footnotes",
    "title": "\n19  Reshaping\n",
    "section": "",
    "text": "Gregory Belenky, Nancy J. Wesensten, David R. Thorne, Maria L. Thomas, Helen C. Sing, Daniel P. Redmond, Michael B. Russo and Thomas J. Balkin (2003) Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. Journal of Sleep Research 12, 1–12.↩︎",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reshaping</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html",
    "href": "ica/ica-joining.html",
    "title": "\n20  Joining\n",
    "section": "",
    "text": "Exercise 1: Where are my keys?",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-joining.html#solutions",
    "href": "ica/ica-joining.html#solutions",
    "title": "\n20  Joining\n",
    "section": "\n20.1 Solutions",
    "text": "20.1 Solutions\n\nClick for Solutions\nExample 1\n\nclass\na student that took ANTH 101\ndata on ART 101\nExample 2\n\nWhat did this do? Linked course info to all students in students_1\n\nWhich observations from students_1 (the left table) were retained? All of them.\nWhich observations from enrollments_1 (the right table) were retained? Only STAT and GEOL, those that matched the students.\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. We retain the courses, not students.\n\n\nenrollments_1 |&gt; \n  left_join(students_1)\n\nJoining with `by = join_by(class)`\n\n\n     class enrollment student\n1 STAT 101         18       A\n2  ART 101         17    &lt;NA&gt;\n3 GEOL 101         24       B\n\n\nExample 3\n\nWhich observations from students_1 (the left table) were retained? A and B, only those with enrollment info.\nWhich observations from enrollments_1 (the right table) were retained? STAT and GEOL, only those with studen info.\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. Same info, different column order.\n\n\nenrollments_1 |&gt; \n    inner_join(students_1)\n\nJoining with `by = join_by(class)`\n\n\n     class enrollment student\n1 STAT 101         18       A\n2 GEOL 101         24       B\n\n\nExample 4\n\nWhich observations from students_1 (the left table) were retained? All\nWhich observations from enrollments_1 (the right table) were retained? All\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. Same data, different order.\n\n\nenrollments_1 |&gt; \n    full_join(students_1)\n\nJoining with `by = join_by(class)`\n\n\n     class enrollment student\n1 STAT 101         18       A\n2  ART 101         17    &lt;NA&gt;\n3 GEOL 101         24       B\n4 ANTH 101         NA       C\n\n\nExample 5\n\nWhich observations from students_1 (the left table) were retained? Only those with enrollment info.\nWhich observations from enrollments_1 (the right table) were retained? None.\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. Same data, different order.\n\n\nenrollments_1 |&gt; \n  semi_join(students_1)\n\nJoining with `by = join_by(class)`\n\n\n     class enrollment\n1 STAT 101         18\n2 GEOL 101         24\n\n\nExample 6\n\nWhich observations from students_1 (the left table) were retained? Only C, the one without enrollment info.\nWhich observations from enrollments_1 (the right table) were retained? None.\nWhat, if anything, would change if we reversed the order of the data tables? Think about it, then try. Retain only ART 101, the course with no student info.\n\n\nenrollments_1 |&gt; \n  anti_join(students_1)\n\nJoining with `by = join_by(class)`\n\n\n    class enrollment\n1 ART 101         17\n\n\nExercise 2: More small practice\n\n# 1. We want contact info for people who HAVEN'T voted\ncontact |&gt; \n  anti_join(voters, join_by(name == id))\n\n  name  address age\n1    B    grand  89\n2    C snelling  43\n\n# 2. We want contact info for people who HAVE voted\ncontact |&gt; \n  semi_join(voters, join_by(name == id))\n\n  name  address age\n1    A   summit  24\n2    D fairview  38\n\n# 3. We want any data available on each person\ncontact |&gt; \n  full_join(voters, join_by(name == id))\n\n  name  address age times_voted\n1    A   summit  24           2\n2    B    grand  89          NA\n3    C snelling  43          NA\n4    D fairview  38           4\n5    E     &lt;NA&gt;  NA          17\n6    F     &lt;NA&gt;  NA           6\n7    G     &lt;NA&gt;  NA          20\n\nvoters |&gt; \n  full_join(contact, join_by(id == name))\n\n  id times_voted  address age\n1  A           2   summit  24\n2  D           4 fairview  38\n3  E          17     &lt;NA&gt;  NA\n4  F           6     &lt;NA&gt;  NA\n5  G          20     &lt;NA&gt;  NA\n6  B          NA    grand  89\n7  C          NA snelling  43\n\n# 4. We want to add contact info, when possible, to the voting roster\nvoters |&gt; \n  left_join(contact, join_by(id == name))\n\n  id times_voted  address age\n1  A           2   summit  24\n2  D           4 fairview  38\n3  E          17     &lt;NA&gt;  NA\n4  F           6     &lt;NA&gt;  NA\n5  G          20     &lt;NA&gt;  NA\n\n\nExercise 3: Bigger datasets\n\n# How many observations (rows) and variables (columns) are there in the grades data?\ndim(grades)\n\n[1] 5844    3\n\n# How many observations (rows) and variables (columns) are there in the courses data?\ndim(courses)\n\n[1] 1718    6\n\n\nExercise 4: Class size\nPart a\n\ncourses_combined &lt;- courses |&gt;\n  group_by(sessionID) |&gt;\n  summarize(enroll = sum(enroll))\n\n# Check that this has 1695 rows and 2 columns\ndim(courses_combined)\n\n[1] 1695    2\n\n\nPart b\n\ncourses_combined |&gt; \n  summarize(median(enroll))\n\nPart c\n\nstudent_class_size &lt;- grades |&gt; \n  left_join(courses_combined) |&gt; \n  group_by(sid) |&gt; \n  summarize(med_class = median(enroll))\n\nhead(student_class_size)\n\nPart d\n\nggplot(student_class_size, aes(x = med_class)) +\n  geom_histogram(color = \"white\")\n\nExercise 5: Narrowing in on classes\nPart a\n\ngrades |&gt; \n  filter(sessionID == \"session1986\")\n\nPart b\n\ngrades |&gt; \n  semi_join(dept_E)\n\nExercise 6: All the wrangling\nPart a\n\ncourses |&gt; \n  group_by(dept) |&gt; \n  summarize(total = sum(enroll)) |&gt; \n  arrange(desc(total))\n\nPart b\n\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  group_by(sid) |&gt; \n  summarize(mean(gp, na.rm = TRUE))\n\nPart c\n\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  group_by(sid) |&gt; \n  summarize(gpa = mean(gp, na.rm = TRUE)) |&gt; \n  summarize(median(gpa))\n\nPart d\n\n# There are lots of approaches here!\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  mutate(below_b_plus = (gp &lt; 3.3)) |&gt; \n  summarize(mean(below_b_plus, na.rm = TRUE))\n\nPart e\n\ngrades |&gt; \n  left_join(gpa_conversion) |&gt; \n  left_join(courses) |&gt; \n  group_by(iid) |&gt; \n  summarize(gpa = mean(gp, na.rm = TRUE)) |&gt; \n  arrange(gpa)\n\nPart f\n\ncross_listed &lt;- courses |&gt; \n  count(sessionID) |&gt; \n  filter(n &gt; 1)\n\ngrades |&gt; \n  anti_join(cross_listed) |&gt; \n  inner_join(courses) |&gt; \n  left_join(gpa_conversion) |&gt; \n  group_by(dept) |&gt; \n  summarize(gpa = mean(gp, na.rm = TRUE)) |&gt; \n  arrange(gpa)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Joining</span>"
    ]
  },
  {
    "objectID": "ica/ica-factors.html",
    "href": "ica/ica-factors.html",
    "title": "\n21  Factors\n",
    "section": "",
    "text": "Exercise 1: Changing Order\nCheck out a column plot of the number of times each grade was assigned during the study period. This is similar to a bar plot, but where we define the height of a bar according to variable in our dataset.\ngrade_distribution |&gt; \n  ggplot(aes(x = grade, y = n)) +\n    geom_col()\nThe order of the grades is goofy! Construct a new column plot, manually reordering the grades from high (A) to low (NC) with “S” and “AU” at the end:\ngrade_distribution |&gt;\n  mutate(grade = fct_relevel(grade, c(\"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"NC\", \"S\", \"AU\"))) |&gt;\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()\nConstruct a new column plot, reordering the grades in ascending frequency (i.e. how often the grades were assigned):\ngrade_distribution |&gt;\n  mutate(grade = fct_reorder(grade, n)) |&gt;\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()\nConstruct a new column plot, reordering the grades in descending frequency (i.e. how often the grades were assigned):\ngrade_distribution |&gt;\n  mutate(grade = fct_reorder(grade, n, .desc = TRUE)) |&gt;\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "ica/ica-factors.html#solutions",
    "href": "ica/ica-factors.html#solutions",
    "title": "\n21  Factors\n",
    "section": "\n21.1 Solutions",
    "text": "21.1 Solutions\n\nClick for Solutions\nExample 1: Default Orde\nThe categories are in alphabetical order, which isn’t meaningful here.\nExample 4: Re-ordering Levels using fct_relevel\n\nwe would have to:\n\nCalculate the typical Republican support in each state, e.g. using group_by() and summarize().\nWe’d then have to manually type out a meaningful order for 50 states! That’s a lot of typing and manual bookkeeping.\nExercise 1: Changing Order\n\ngrade_distribution |&gt;\n  mutate(grade = fct_relevel(grade, c(\"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"NC\", \"S\", \"AU\"))) |&gt;\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()\n\n\n\n\n\n\n\n\ngrade_distribution |&gt;\n  mutate(grade = fct_reorder(grade, n)) |&gt;\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()\n\n\n\n\n\n\n\n\ngrade_distribution |&gt;\n  mutate(grade = fct_reorder(grade, n, .desc = TRUE)) |&gt;\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()\n\n\n\n\n\n\n\nExercise 2: Changing Factor Level Labels\n\ngrade_distribution |&gt;\n  mutate(grade = fct_relevel(grade, c(\"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"NC\", \"S\", \"AU\"))) |&gt;\n  mutate(grade = fct_recode(grade, \"Satisfactory\" = \"S\", \"Audit\" = \"AU\")) |&gt;  # Multiple pieces go into the last 2 blanks\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Factors</span>"
    ]
  },
  {
    "objectID": "ica/ica-strings.html",
    "href": "ica/ica-strings.html",
    "title": "\n22  Strings\n",
    "section": "",
    "text": "Exercise 1: Time slots\nThe courses data includes actual data scraped from Mac’s class schedule. (Thanks to Prof Leslie Myint for the scraping code!!)\nIf you want to learn how to scrape data, take COMP/STAT 212, Intermediate Data Science! NOTE: For simplicity, I removed classes that had “TBA” for the days.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ncourses &lt;- read.csv(\"https://mac-stat.github.io/data/registrar.csv\")\n\n# Check it out\nhead(courses)\n\n       number   crn                                                name  days\n1 AMST 112-01 10318         Introduction to African American Literature M W F\n2 AMST 194-01 10073              Introduction to Asian American Studies M W F\n3 AMST 194-F1 10072 What’s After White Empire - And Is It Already Here?  T R \n4 AMST 203-01 10646 Politics and Inequality: The American Welfare State M W F\n5 AMST 205-01 10842                         Trans Theories and Politics  T R \n6 AMST 209-01 10474                   Civil Rights in the United States   W  \n             time      room             instructor avail_max\n1 9:40 - 10:40 am  MAIN 009       Daylanne English    3 / 20\n2  1:10 - 2:10 pm MUSIC 219          Jake Nagasawa   -4 / 16\n3  3:00 - 4:30 pm   HUM 214 Karin Aguilar-San Juan    0 / 14\n4 9:40 - 10:40 am  CARN 305          Lesley Lavery    3 / 25\n5  3:00 - 4:30 pm  MAIN 009              Myrl Beam   -2 / 20\n6 7:00 - 10:00 pm  MAIN 010         Walter Greason   -1 / 15\nUse our more familiar wrangling tools to warm up.\n# Construct a table that indicates the number of classes offered in each day/time slot\n# Print only the 6 most popular time slots\n\ncourses |&gt;\n  count(days, time) |&gt;\n  arrange(desc(n)) |&gt;\n  head()\n\n   days             time  n\n1 M W F 10:50 - 11:50 am 76\n2  T R   9:40 - 11:10 am 71\n3 M W F  9:40 - 10:40 am 68\n4 M W F   1:10 - 2:10 pm 66\n5  T R    3:00 - 4:30 pm 62\n6  T R    1:20 - 2:50 pm 59",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "ica/ica-strings.html#solutions",
    "href": "ica/ica-strings.html#solutions",
    "title": "\n22  Strings\n",
    "section": "\n22.1 Solutions",
    "text": "22.1 Solutions\n\nClick for Solutions\nExercise 1: Popular time slots\n\n# Construct a table that indicates the number of classes offered in each day/time slot\n# Print only the 6 most popular time slots\ncourses |&gt; \n  count(days, time) |&gt; \n  arrange(desc(n)) |&gt; \n  head()\n\n   days             time  n\n1 M W F 10:50 - 11:50 am 76\n2  T R   9:40 - 11:10 am 71\n3 M W F  9:40 - 10:40 am 68\n4 M W F   1:10 - 2:10 pm 66\n5  T R    3:00 - 4:30 pm 62\n6  T R    1:20 - 2:50 pm 59\n\n\nExercise 2: Prep the data\n\ncourses_clean &lt;- courses |&gt; \n  separate(avail_max, c(\"avail\", \"max\"), sep = \" / \") |&gt; \n  mutate(enroll = as.numeric(max) - as.numeric(avail)) |&gt; \n  separate(number, c(\"dept\", \"number\", \"section\"))\n  \nhead(courses_clean)\n\n  dept number section   crn                                                name\n1 AMST    112      01 10318         Introduction to African American Literature\n2 AMST    194      01 10073              Introduction to Asian American Studies\n3 AMST    194      F1 10072 What’s After White Empire - And Is It Already Here?\n4 AMST    203      01 10646 Politics and Inequality: The American Welfare State\n5 AMST    205      01 10842                         Trans Theories and Politics\n6 AMST    209      01 10474                   Civil Rights in the United States\n   days            time      room             instructor avail max enroll\n1 M W F 9:40 - 10:40 am  MAIN 009       Daylanne English     3  20     17\n2 M W F  1:10 - 2:10 pm MUSIC 219          Jake Nagasawa    -4  16     20\n3  T R   3:00 - 4:30 pm   HUM 214 Karin Aguilar-San Juan     0  14     14\n4 M W F 9:40 - 10:40 am  CARN 305          Lesley Lavery     3  25     22\n5  T R   3:00 - 4:30 pm  MAIN 009              Myrl Beam    -2  20     22\n6   W   7:00 - 10:00 pm  MAIN 010         Walter Greason    -1  15     16\n\n\nExercise 3: Courses offered by department\n\n# Identify the 6 departments that offered the most sections\ncourses_clean |&gt; \n  count(dept) |&gt; \n  arrange(desc(n)) |&gt; \n  head()\n\n  dept  n\n1 SPAN 45\n2 BIOL 44\n3 ENVI 38\n4 PSYC 37\n5 CHEM 33\n6 COMP 31\n\n# Identify the 6 departments with the longest average course titles\ncourses_clean |&gt; \n  mutate(length = str_length(name)) |&gt; \n  group_by(dept) |&gt; \n  summarize(avg_length = mean(length)) |&gt; \n  arrange(desc(avg_length)) |&gt; \n  head()\n\n# A tibble: 6 × 2\n  dept  avg_length\n  &lt;chr&gt;      &lt;dbl&gt;\n1 WGSS        46.3\n2 INTL        41.4\n3 EDUC        39.4\n4 MCST        39.4\n5 POLI        37.4\n6 AMST        37.3\n\n\nExercise 4: STAT courses\nPart a\n\ncourses_clean |&gt; \n  filter(str_detect(instructor, \"Alicia Johnson\")) \n\n  dept number section   crn                         name  days            time\n1 STAT    253      01 10806 Statistical Machine Learning  T R  9:40 - 11:10 am\n2 STAT    253      02 10807 Statistical Machine Learning  T R   1:20 - 2:50 pm\n3 STAT    253      03 10808 Statistical Machine Learning  T R   3:00 - 4:30 pm\n        room     instructor avail max enroll\n1 THEATR 206 Alicia Johnson    -3  20     23\n2 THEATR 206 Alicia Johnson    -3  20     23\n3 THEATR 206 Alicia Johnson     2  20     18\n\n\nPart b\n\nstat &lt;- courses_clean |&gt; \n  filter(dept == \"STAT\") |&gt; \n  mutate(name = str_replace(name, \"Introduction to \", \"\")) |&gt;\n  mutate(name = str_replace(name, \"Statistical\", \"Stat\")) |&gt; \n  mutate(start_time = str_sub(time, 1, 5)) |&gt; \n  select(number, name, start_time, enroll)\n\nstat\n\n   number                      name start_time enroll\n1     112              Data Science      3:00      27\n2     112              Data Science      9:40      21\n3     112              Data Science      1:20      25\n4     125              Epidemiology      12:00     26\n5     155             Stat Modeling      1:10      32\n6     155             Stat Modeling      9:40      24\n7     155             Stat Modeling      10:50     26\n8     155             Stat Modeling      3:30      25\n9     155             Stat Modeling      1:20      30\n10    155             Stat Modeling      3:00      27\n11    212 Intermediate Data Science      9:40      11\n12    212 Intermediate Data Science      1:20      11\n13    253     Stat Machine Learning      9:40      23\n14    253     Stat Machine Learning      1:20      23\n15    253     Stat Machine Learning      3:00      18\n16    354               Probability      3:00      22\n17    452           Correlated Data      9:40       7\n18    452           Correlated Data      1:20       8\n19    456  Projects in Data Science      9:40      11\n\ndim(stat)\n\n[1] 19  4\n\n\nExercise 5: More cleaning\n\nenrollments &lt;- courses_clean |&gt; \n  filter(dept != \"PE\", dept != \"INTD\") |&gt; \n  filter(!(dept == \"MUSI\" & as.numeric(number) &lt; 100)) |&gt; \n  filter(!(dept == \"THDA\" & as.numeric(number) &lt; 100)) |&gt; \n  filter(!str_detect(section, \"L\"))\n  \nhead(enrollments)\n\n  dept number section   crn                                                name\n1 AMST    112      01 10318         Introduction to African American Literature\n2 AMST    194      01 10073              Introduction to Asian American Studies\n3 AMST    194      F1 10072 What’s After White Empire - And Is It Already Here?\n4 AMST    203      01 10646 Politics and Inequality: The American Welfare State\n5 AMST    205      01 10842                         Trans Theories and Politics\n6 AMST    209      01 10474                   Civil Rights in the United States\n   days            time      room             instructor avail max enroll\n1 M W F 9:40 - 10:40 am  MAIN 009       Daylanne English     3  20     17\n2 M W F  1:10 - 2:10 pm MUSIC 219          Jake Nagasawa    -4  16     20\n3  T R   3:00 - 4:30 pm   HUM 214 Karin Aguilar-San Juan     0  14     14\n4 M W F 9:40 - 10:40 am  CARN 305          Lesley Lavery     3  25     22\n5  T R   3:00 - 4:30 pm  MAIN 009              Myrl Beam    -2  20     22\n6   W   7:00 - 10:00 pm  MAIN 010         Walter Greason    -1  15     16\n\n\nOptional extra practice\n\n# Make a bar plot showing the number of night courses by day of the week.\ncourses_clean |&gt; \n  filter(str_detect(time, \"7:00\")) |&gt; \n  ggplot(aes(x = days)) + \n    geom_bar()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "ica/ica-data_import.html",
    "href": "ica/ica-data_import.html",
    "title": "\n23  Data Import\n",
    "section": "",
    "text": "Exercise 1: Save Data Locally",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Data Import</span>"
    ]
  },
  {
    "objectID": "ica/ica-data_import.html#solutions",
    "href": "ica/ica-data_import.html#solutions",
    "title": "\n23  Data Import\n",
    "section": "\n23.1 Solutions",
    "text": "23.1 Solutions\n\nClick for Solutions\n\n\nNew names:\nRows: 5043 Columns: 29\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(12): color, director_name, actor_2_name, genres, actor_1_name, movie_ti... dbl\n(17): ...1, num_critic_for_reviews, duration, director_facebook_likes, a...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\nExercise 3: Check Data\nPart b\nThere are many NA’s, the color variable is goofy…\n\nimdb_messy |&gt;\n  mutate(across(where(is.character), as.factor)) |&gt;  # convert characters to factors in order to summarize\n  summary()\n\n      ...1                  color               director_name \n Min.   :   1   B&W            :  10   Steven Spielberg:  26  \n 1st Qu.:1262   Black and White: 199   Woody Allen     :  22  \n Median :2522   color          :  30   Clint Eastwood  :  20  \n Mean   :2522   Color          :4755   Martin Scorsese :  20  \n 3rd Qu.:3782   COLOR          :  30   Ridley Scott    :  17  \n Max.   :5043   NA's           :  19   (Other)         :4834  \n                                       NA's            : 104  \n num_critic_for_reviews    duration     director_facebook_likes\n Min.   :  1.0          Min.   :  7.0   Min.   :    0.0        \n 1st Qu.: 50.0          1st Qu.: 93.0   1st Qu.:    7.0        \n Median :110.0          Median :103.0   Median :   49.0        \n Mean   :140.2          Mean   :107.2   Mean   :  686.5        \n 3rd Qu.:195.0          3rd Qu.:118.0   3rd Qu.:  194.5        \n Max.   :813.0          Max.   :511.0   Max.   :23000.0        \n NA's   :50             NA's   :15      NA's   :104            \n actor_3_facebook_likes          actor_2_name  actor_1_facebook_likes\n Min.   :    0.0        Morgan Freeman :  20   Min.   :     0        \n 1st Qu.:  133.0        Charlize Theron:  15   1st Qu.:   614        \n Median :  371.5        Brad Pitt      :  14   Median :   988        \n Mean   :  645.0        James Franco   :  11   Mean   :  6560        \n 3rd Qu.:  636.0        Meryl Streep   :  11   3rd Qu.: 11000        \n Max.   :23000.0        (Other)        :4959   Max.   :640000        \n NA's   :23             NA's           :  13   NA's   :7             \n     gross                            genres             actor_1_name \n Min.   :      162   Drama               : 236   Robert De Niro:  49  \n 1st Qu.:  5340988   Comedy              : 209   Johnny Depp   :  41  \n Median : 25517500   Comedy|Drama        : 191   Nicolas Cage  :  33  \n Mean   : 48468408   Comedy|Drama|Romance: 187   J.K. Simmons  :  31  \n 3rd Qu.: 62309438   Comedy|Romance      : 158   Bruce Willis  :  30  \n Max.   :760505847   Drama|Romance       : 152   (Other)       :4852  \n NA's   :884         (Other)             :3910   NA's          :   7  \n                    movie_title   num_voted_users   cast_total_facebook_likes\n Ben-Hur                  :   3   Min.   :      5   Min.   :     0           \n Halloween                :   3   1st Qu.:   8594   1st Qu.:  1411           \n Home                     :   3   Median :  34359   Median :  3090           \n King Kong                :   3   Mean   :  83668   Mean   :  9699           \n Pan                      :   3   3rd Qu.:  96309   3rd Qu.: 13756           \n The Fast and the Furious :   3   Max.   :1689764   Max.   :656730           \n (Other)                  :5025                                              \n         actor_3_name  facenumber_in_poster\n Ben Mendelsohn:   8   Min.   : 0.000      \n John Heard    :   8   1st Qu.: 0.000      \n Steve Coogan  :   8   Median : 1.000      \n Anne Hathaway :   7   Mean   : 1.371      \n Jon Gries     :   7   3rd Qu.: 2.000      \n (Other)       :4982   Max.   :43.000      \n NA's          :  23   NA's   :13          \n                                                                           plot_keywords \n based on novel                                                                   :   4  \n 1940s|child hero|fantasy world|orphan|reference to peter pan                     :   3  \n alien friendship|alien invasion|australia|flying car|mother daughter relationship:   3  \n animal name in title|ape abducts a woman|gorilla|island|king kong                :   3  \n assistant|experiment|frankenstein|medical student|scientist                      :   3  \n (Other)                                                                          :4874  \n NA's                                                                             : 153  \n                                             movie_imdb_link\n http://www.imdb.com/title/tt0077651/?ref_=fn_tt_tt_1:   3  \n http://www.imdb.com/title/tt0232500/?ref_=fn_tt_tt_1:   3  \n http://www.imdb.com/title/tt0360717/?ref_=fn_tt_tt_1:   3  \n http://www.imdb.com/title/tt1976009/?ref_=fn_tt_tt_1:   3  \n http://www.imdb.com/title/tt2224026/?ref_=fn_tt_tt_1:   3  \n http://www.imdb.com/title/tt2638144/?ref_=fn_tt_tt_1:   3  \n (Other)                                             :5025  \n num_user_for_reviews     language       country       content_rating\n Min.   :   1.0       English :4704   USA    :3807   R        :2118  \n 1st Qu.:  65.0       French  :  73   UK     : 448   PG-13    :1461  \n Median : 156.0       Spanish :  40   France : 154   PG       : 701  \n Mean   : 272.8       Hindi   :  28   Canada : 126   Not Rated: 116  \n 3rd Qu.: 326.0       Mandarin:  26   Germany:  97   G        : 112  \n Max.   :5060.0       (Other) : 160   (Other): 406   (Other)  : 232  \n NA's   :21           NA's    :  12   NA's   :   5   NA's     : 303  \n     budget            title_year   actor_2_facebook_likes   imdb_score   \n Min.   :2.180e+02   Min.   :1916   Min.   :     0         Min.   :1.600  \n 1st Qu.:6.000e+06   1st Qu.:1999   1st Qu.:   281         1st Qu.:5.800  \n Median :2.000e+07   Median :2005   Median :   595         Median :6.600  \n Mean   :3.975e+07   Mean   :2002   Mean   :  1652         Mean   :6.442  \n 3rd Qu.:4.500e+07   3rd Qu.:2011   3rd Qu.:   918         3rd Qu.:7.200  \n Max.   :1.222e+10   Max.   :2016   Max.   :137000         Max.   :9.500  \n NA's   :492         NA's   :108    NA's   :13                            \n  aspect_ratio   movie_facebook_likes\n Min.   : 1.18   Min.   :     0      \n 1st Qu.: 1.85   1st Qu.:     0      \n Median : 2.35   Median :   166      \n Mean   : 2.22   Mean   :  7526      \n 3rd Qu.: 2.35   3rd Qu.:  3000      \n Max.   :16.00   Max.   :349000      \n NA's   :329                         \n\n\nExercise 4: Clean Data: Factor Variables 1\n\nimdb_messy |&gt; \n  count(color)\n\n# A tibble: 6 × 2\n  color               n\n  &lt;chr&gt;           &lt;int&gt;\n1 B&W                10\n2 Black and White   199\n3 COLOR              30\n4 Color            4755\n5 color              30\n6 &lt;NA&gt;               19\n\n\nExercise 5: Clean Data: Factor Variables 2\nPart a\nThat wouldn’t be reproducible. It’s important to log all steps in our data cleaning, so that we and others know and could reproduce those steps.\nPart b\n\nimdb_temp &lt;- imdb_messy |&gt; \n  mutate(color = fct_recode(color,\n                            \"Color\" = \"COLOR\",\n                            \"Color\" = \"color\",\n                            \"Black_White\" = \"B&W\",\n                            \"Black_White\" = \"Black and White\"))\n\nimdb_temp |&gt; \n  count(color)\n\n# A tibble: 3 × 2\n  color           n\n  &lt;fct&gt;       &lt;int&gt;\n1 Black_White   209\n2 Color        4815\n3 &lt;NA&gt;           19\n\n\nPart c\n\nimdb_temp &lt;- imdb_messy |&gt; \n  mutate(color = str_replace(color, \"COLOR\", \"Color\"),\n         color = str_replace(color, \"color\", \"Color\"),\n         color = str_replace(color, \"B&W\", \"Black_White\"),\n         color = str_replace(color, \"Black and White\", \"Black_White\"))\n\nimdb_temp |&gt; \n  count(color)\n\n# A tibble: 3 × 2\n  color           n\n  &lt;chr&gt;       &lt;int&gt;\n1 Black_White   209\n2 Color        4815\n3 &lt;NA&gt;           19\n\n\nExercise 6: Clean Data: Missing Data 1\nPart a\n\n# Count the total number of rows in imdb_messy\nnrow(imdb_messy)\n\n[1] 5043\n\n# Then count the number of NAs in each column\ncolSums(is.na(imdb_messy))\n\n                     ...1                     color             director_name \n                        0                        19                       104 \n   num_critic_for_reviews                  duration   director_facebook_likes \n                       50                        15                       104 \n   actor_3_facebook_likes              actor_2_name    actor_1_facebook_likes \n                       23                        13                         7 \n                    gross                    genres              actor_1_name \n                      884                         0                         7 \n              movie_title           num_voted_users cast_total_facebook_likes \n                        0                         0                         0 \n             actor_3_name      facenumber_in_poster             plot_keywords \n                       23                        13                       153 \n          movie_imdb_link      num_user_for_reviews                  language \n                        0                        21                        12 \n                  country            content_rating                    budget \n                        5                       303                       492 \n               title_year    actor_2_facebook_likes                imdb_score \n                      108                        13                         0 \n             aspect_ratio      movie_facebook_likes \n                      329                         0 \n\n\nPart c\nThese are all documentaries that don’t have any actors.\n\nimdb_messy |&gt; \n  filter(is.na(actor_1_facebook_likes))\n\n# A tibble: 7 × 29\n   ...1 color director_name     num_critic_for_reviews duration\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                              &lt;dbl&gt;    &lt;dbl&gt;\n1  4503 Color Léa Pool                              23       97\n2  4520 Color Harry Gantz                           12      105\n3  4721 Color U. Roberto Romano                      3       80\n4  4838 Color Pan Nalin                             15      102\n5  4946 Color Amal Al-Agroobi                       NA       62\n6  4947 Color Andrew Berends                        12       90\n7  4991 Color Jem Cohen                             12      111\n# ℹ 24 more variables: director_facebook_likes &lt;dbl&gt;,\n#   actor_3_facebook_likes &lt;dbl&gt;, actor_2_name &lt;chr&gt;,\n#   actor_1_facebook_likes &lt;dbl&gt;, gross &lt;dbl&gt;, genres &lt;chr&gt;,\n#   actor_1_name &lt;chr&gt;, movie_title &lt;chr&gt;, num_voted_users &lt;dbl&gt;,\n#   cast_total_facebook_likes &lt;dbl&gt;, actor_3_name &lt;chr&gt;,\n#   facenumber_in_poster &lt;dbl&gt;, plot_keywords &lt;chr&gt;, movie_imdb_link &lt;chr&gt;,\n#   num_user_for_reviews &lt;dbl&gt;, language &lt;chr&gt;, country &lt;chr&gt;, …\n\n\nExercise 7: Clean: Missing Data 2\nPart a\n\nimdb_messy |&gt; \n  summarize(mean(duration, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  `mean(duration, na.rm = TRUE)`\n                           &lt;dbl&gt;\n1                           107.\n\n\nFollow-up:\nWe just remove the NAs from the calculation. No need to entirely remove the related movies from the dataset.\nPart b\nThis gets rid of any movie with any NAs. There are only 3756 movies left! This approach is heavy-handed. It’s typically only a good idea when we need complete info on every variable for every part of our analysis.\n\nimdb_temp &lt;- drop_na(imdb_messy)\nnrow(imdb_temp)\n\n[1] 3756\n\ncolSums(is.na(imdb_temp))\n\n                     ...1                     color             director_name \n                        0                         0                         0 \n   num_critic_for_reviews                  duration   director_facebook_likes \n                        0                         0                         0 \n   actor_3_facebook_likes              actor_2_name    actor_1_facebook_likes \n                        0                         0                         0 \n                    gross                    genres              actor_1_name \n                        0                         0                         0 \n              movie_title           num_voted_users cast_total_facebook_likes \n                        0                         0                         0 \n             actor_3_name      facenumber_in_poster             plot_keywords \n                        0                         0                         0 \n          movie_imdb_link      num_user_for_reviews                  language \n                        0                         0                         0 \n                  country            content_rating                    budget \n                        0                         0                         0 \n               title_year    actor_2_facebook_likes                imdb_score \n                        0                         0                         0 \n             aspect_ratio      movie_facebook_likes \n                        0                         0 \n\n\nPart c\n\nggplot(imdb_messy, aes(x = duration, fill = color)) +\n  geom_density()\n\nWarning: Removed 15 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\nWe keep most of the movies!\n\n# Approach 1\nimdb_temp &lt;- imdb_messy |&gt; \n  select(duration, color) |&gt; \n  drop_na()\ndim(imdb_temp)\n\n[1] 5010    2\n\n# Approach 2\nimdb_temp &lt;- imdb_messy |&gt; \n  filter(!is.na(duration), !is.na(color))\ndim(imdb_temp)\n\n[1] 5010   29\n\n# Plot\nggplot(imdb_temp, aes(x = duration, fill = color)) +\n  geom_density()\n\n\n\n\n\n\n\nPart d\n\nimdb_temp &lt;- imdb_messy |&gt; \n  mutate(actor_1_facebook_likes =\n         replace_na(actor_1_facebook_likes, 0))\n\nimdb_temp |&gt; \n  summarize(sum(is.na(actor_1_facebook_likes)))\n\n# A tibble: 1 × 1\n  `sum(is.na(actor_1_facebook_likes))`\n                                 &lt;int&gt;\n1                                    0",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Data Import</span>"
    ]
  }
]